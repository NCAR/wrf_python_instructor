{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# WRF-Python and VAPOR Workshop 2018\n",
    "<p></p>\n",
    "\n",
    "\n",
    "## Bill Ladwig\n",
    "## NCAR/CISL/VAST\n",
    "## September 26-27, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# What is WRF-Python?\n",
    "\n",
    "- WRF-Python is a post-processing tool similar to NCL's WRF Package.\n",
    "  - Contains over 30 diagnostic routines (CAPE, storm relative helicity, cloud top temperature, etc).\n",
    "  - Interpolation routines (level, cross section, surface).\n",
    "  - Utilities to help with plotting via cartopy, basemap, PyNGL.\n",
    "- WRF-ARW only.\n",
    "- WRF-Python is **NOT** a tool for running the WRF-ARW model with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Topics\n",
    "\n",
    "1. Installation using conda\n",
    "1. Introduction to jupyter notebooks, numpy, xarray\n",
    "1. Overview of WRF-ARW Output Data\n",
    "1. WRF-Python Functions\n",
    "1. Plotting\n",
    "1. OpenMP and Performance\n",
    "1. Advanced\n",
    "1. Open Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1.0 Installation Using Conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is conda?\n",
    "\n",
    "- Conda is a package manager for scientific software.\n",
    "- Installs and removes pre-built software packages.\n",
    "- Originally made for distributing binary Python packages, but other binaries \n",
    "  like NCL are available as well.\n",
    "- Can be used to create isolated environments, similar to *virtualenv* (conda environments).\n",
    "- Included with Anaconda and Miniconda Python distributions (prefer Miniconda with conda-forge)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Anaconda?\n",
    "- A scientific Python distribution containing many hard to build Python packages (e.g. numpy, scipy).\n",
    "- Attempts to be an all-in-one scientific Python solution.\n",
    "- Does not play well with packages from other channels (e.g. conda-forge).\n",
    "- Releases are infrequent.\n",
    "- Only a limited number of packages available.\n",
    "- Maintained by Anaconda, Inc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Miniconda?\n",
    "- Bare bones installation (conda package manager only).\n",
    "- Works well with the conda-forge channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is conda-forge?\n",
    "- A community driven channel for the conda package manager.\n",
    "- Contains hundreds of packages not available for Anaconda.\n",
    "- Uses continuous integration services to ensure packages run correctly and play well with others.\n",
    "- Package conflicts occasionally arise when packages are updated.\n",
    "- Releases happen frequently.\n",
    "- Maintained by open source community.\n",
    "\n",
    "**We will be using Miniconda with conda-forge for this tutorial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Step 1: Download Miniconda (Laptop Users)\n",
    "\n",
    "https://conda.io/miniconda.html\n",
    "\n",
    "You can use either the Python 2.7 or 3.7 version. \n",
    "\n",
    "We'll be creating a Python 3.6 conda environment for the tutorial, which does not depend on the version of Miniconda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Step 2: Open a Command Prompt (All Users)\n",
    "\n",
    "Windows:\n",
    "\n",
    "```\n",
    "WINDOWS + r; \n",
    "type cmd in run window\n",
    "\n",
    "For Windows 10:\n",
    "Start Menu -> Anaconda2 -> Anaconda Prompt\n",
    "\n",
    "```\n",
    "\n",
    "Mac: \n",
    "\n",
    "```\n",
    "Finder -> Applications -> Utilities -> Terminal\n",
    "```\n",
    "\n",
    "Linux:\n",
    "\n",
    "```\n",
    "Try one of the following:\n",
    "\n",
    "CTRL + ALT + T (Use Activities Menu)\n",
    "CTRL + ALT + F2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Step 3: Install Miniconda (Laptop Users)\n",
    "\n",
    "For Windows: Double click on the installer and follow the instructions\n",
    "\n",
    "For Linux and Mac:\n",
    "\n",
    "```\n",
    "bash /path/to/Miniconda2-latest-MacOSX-x86_64.sh [Mac]\n",
    "\n",
    "bash /path/to/Miniconda2-latest-Linux-x86_64.sh [Linux]\n",
    "\n",
    "```\n",
    "Restart your terminal. \n",
    "\n",
    "**Make sure you're using bash.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Step 4: Set Up the conda Environment (All Users)\n",
    "\n",
    "We want to use miniconda with the conda-forge channel.\n",
    "\n",
    "Type the command below, all on one line.\n",
    "```\n",
    "conda create -c conda-forge -n workshop_2018 \n",
    "    python=3.6 matplotlib cartopy netcdf4 jupyter \n",
    "    git ffmpeg wrf-python\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Step 5: Activate the conda Environment (All Users)\n",
    "\n",
    "Mac and Linux:\n",
    "\n",
    "```\n",
    "source activate workshop_2018\n",
    "\n",
    "(To deactivate: source deactivate)\n",
    "\n",
    "```\n",
    "\n",
    "Windows:\n",
    "\n",
    "```\n",
    "activate workshop_2018\n",
    "\n",
    "(To deactivate: deactivate)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Step 6: Download the Student Workbook to Your Home Directory (Laptop Users)\n",
    "\n",
    "Go to your home directory:\n",
    "```\n",
    "cd ~ [Mac/Linux]\n",
    "cd %HOMEPATH% [Windows]\n",
    "```\n",
    "\n",
    "Download the GIT repository (type on one line):\n",
    "```\n",
    "git clone\n",
    "  https://github.com/NCAR/wrf_python_tutorial.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Step 7: Download and Unzip Sample WRF Data to Home Directory (Laptop Users)\n",
    "\n",
    "https://amzn.to/2QpKWev\n",
    "\n",
    "Click the check box next to wrf_tutorial_data.zip and select Download at the top.\n",
    "\n",
    "Unzip the data to your home directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2.0 Introduction to jupyter, numpy, xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Jupyter Notebook?\n",
    "\n",
    "- Originally IPython Notebook (now Julia, Python, R)\n",
    "- The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. \n",
    "\n",
    "- The Jupyter Notebook actually consists of a document and an application\n",
    "\n",
    "- The Jupyter Notebook application is a web browser application that allows editing and executing of jupyter notebook documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Jupyter Notebook?\n",
    "\n",
    "- Jupyter Notebook documents (ending with a .ipynb extension), are really just JSON-formatted text files that contain the code and rich text elements that will be rendered by the jupyter notebook application.  \n",
    "\n",
    "- Jupyter notebook documents are NOT Python scripts, so do not try to run them via the 'python' command.  They need to be converted first.\n",
    "\n",
    "- For this tutorial, when we refer to jupyter notebook, we're referring to both the application and document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Activating Your Conda Environment\n",
    "\n",
    "If you followed the installation instructions (or using a lab computer), you should have created a \"workshop_2018\" conda environment.  \n",
    "\n",
    "To activate it, first open a terminal and type in:\n",
    "\n",
    "```\n",
    "source activate workshop_2018 [Linux/Mac]\n",
    "\n",
    "activate workshop_2018 [Windows]\n",
    "```\n",
    "\n",
    "A **tutorial_backup** environment is available on the workstations if you had trouble earlier. \n",
    "\n",
    "Raise your hand if you need help. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pulling Down the Latest Changes\n",
    "\n",
    "```\n",
    "\n",
    "cd ~/wrf_python_tutorial\n",
    "\n",
    "[cd %HOMEPATH%\\wrf_python_tutorial]\n",
    "\n",
    "git checkout -- .\n",
    "\n",
    "git pull\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Starting jupyter notebook\n",
    "\n",
    "Linux/Mac:\n",
    "```\n",
    "cd ~\n",
    "cd wrf_python_tutorial/boise_workshop_2018\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "Windows:\n",
    "```\n",
    "cd %HOMEPATH%\n",
    "cd wrf_python_tutorial\\boise_workshop_2018\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "If for some reason the browser does not launch automatically, open a web browser and copy the URL listed on your command terminal:\n",
    "\n",
    "```\n",
    "http://localhost:8888/?token=...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Your web browser should look similar to this:\n",
    " \n",
    "![alt](images/jupyter_home.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now click on the **boise_workshop_2018.ipynb** link.  \n",
    "\n",
    "This should open a new browser tab that looks like:\n",
    "\n",
    "![alt](images/jupyter_workbook.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cells\n",
    "\n",
    "- A jupyter notebook is a collection of cells, similar to Mathematica.\n",
    "\n",
    "- Cells can be either executable code or text (markdown).\n",
    "\n",
    "- Cells can also be specified as slides, which is how this slide show was made (using the jupyter Rise plugin)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cells\n",
    "\n",
    "- Entering and executing code in cells is the same as having typed it in to the Python \n",
    "  shell program.\n",
    "- The order of execution of the cells can have impacts on variables that are used across\n",
    "  the cells, so be careful when re-running cells.\n",
    "- Aside from the first cell you run, the cells used in this tutorial should be more like\n",
    "  independent scripts.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Executing Cells\n",
    "\n",
    "1. Click on the desired cell.\n",
    "2. Press **CTRL + RETURN** to execute the cell or press **SHIFT + RETURN** to execute the cell and advance to the next cell.\n",
    "3. Alternatively, you can use the Cell dropdown menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Restarting the Notebook\n",
    "\n",
    "If your notebook crashes for some reason:\n",
    "\n",
    "1. Use the Kernel dropdown menu at the top.\n",
    "2. Execute Kernel -> Restart & Clear Output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Shutting down the notebook\n",
    "\n",
    "1. On your web browser, select the Home tab.\n",
    "2. Click the check box next to boise_workshop_2018.ipynb.\n",
    "3. Click the Shutdown button that will become available after step 2.\n",
    "4. Now go to the terminal window where you typed in \"jupyter notebook\".\n",
    "5. With the terminal window active, press **CTRL + C**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 2.1 Verifying your Jupyter Environment\n",
    "\n",
    "To set up the tutorial to work with your files, **modify the WRF_DIRECTORY and WRF_FILES variables** to point to your WRF files.\n",
    "\n",
    "**IMPORTANT**:  If for some reason your workbook crashes, you need to run this cell again before running the later examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# This jupyter notebook command inserts matplotlib graphics in \n",
    "# to the workbook\n",
    "%matplotlib inline\n",
    "\n",
    "# Modify these to point to your own files\n",
    "WRF_DIRECTORY = \"~/wrf_tutorial_data\"\n",
    "WRF_FILES = [\"wrfout_d01_2010-06-02_00_00_00\",\n",
    "             \"wrfout_d01_2010-06-03_00_00_00\",\n",
    "             \"wrfout_d01_2010-06-04_00_00_00\"]\n",
    "\n",
    "\n",
    "# Do not modify the code below this line\n",
    "#------------------------------------------------------\n",
    "# Turn off annoying warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Make sure the environment is good\n",
    "import numpy\n",
    "import cartopy\n",
    "import matplotlib\n",
    "from netCDF4 import Dataset\n",
    "from xarray import DataArray\n",
    "from wrf import (getvar, interplevel, vertcross, \n",
    "                 vinterp, ALL_TIMES)\n",
    "import os\n",
    "\n",
    "_WRF_FILES = [os.path.abspath(os.path.expanduser(\n",
    "    os.path.join(WRF_DIRECTORY, f))) for f in WRF_FILES]\n",
    "\n",
    "# Check that the WRF files exist\n",
    "for f in _WRF_FILES:\n",
    "    if not os.path.exists(f):\n",
    "        raise ValueError(\"{} does not exist. \"\n",
    "            \"Check for typos or incorrect directory.\".format(f))\n",
    "\n",
    "# Create functions so that the WRF files only need\n",
    "# to be specified using the WRF_FILES global above\n",
    "def single_wrf_file():\n",
    "    global _WRF_FILES\n",
    "    return _WRF_FILES[0]\n",
    "\n",
    "def multiple_wrf_files():\n",
    "    global _WRF_FILES\n",
    "    return _WRF_FILES\n",
    "\n",
    "print (\"All tests passed!\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Numpy\n",
    "\n",
    "- Numpy is a Python package for performing array based operations, similar to Matlab and NCL.\n",
    "- Numpy arrays can be created for the common types in C (named \"dtype\" in numpy)\n",
    "  - int8, int16, int32, int64 (and unsigned versions)\n",
    "  - float16, float32, float64 [default]\n",
    "  - bool\n",
    "  - complex64, complex128\n",
    "- Arrays can be C-ordered (fastest on right) or Fortran-ordered (fastest on left).  C-ordered by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Numpy Basics\n",
    "\n",
    "## Array Creation\n",
    "\n",
    "In this example, we're going to create an array of all zeros with 3x3x3 shape.\n",
    "\n",
    "Here is how to create an array of floats and then integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "array_float32 = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "array_int32 = numpy.zeros((3,3,3), \"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Accessing Elements\n",
    "\n",
    "- To access elements in numpy, you use the bracket \"[ ]\" syntax.  \n",
    "\n",
    "- Supply each desired index separated by commas (this is really a tuple).\n",
    "\n",
    "- You can use also negative indexes to pick indexes from the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "# Accessing elements\n",
    "first_element = my_array[0,0,0]\n",
    "\n",
    "last_element = my_array[-1,-1,-1]\n",
    "\n",
    "mid_element = my_array[1,1,1]\n",
    "\n",
    "# Setting an element\n",
    "my_array[1,1,1] = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Slices\n",
    "\n",
    "- Slices are a way to extract array subsets from an array.\n",
    "- The syntax for a slice is the ':' character.\n",
    "- Specifying the ':' for a dimension will return all values along that dimension.\n",
    "- Specifying 'start : end' will take a subset of that dimension. Also, either *start* or *end* can be left blank.\n",
    "- The *end* index is NOT included in the slice (opposite of NCL).\n",
    "- Can also use a *step* value with 'start : end : step' if you want to increment values with something other than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "first_row = my_array[0,0,:]\n",
    "\n",
    "first_column = my_array[0,:,0]\n",
    "\n",
    "first_z = my_array[:,0,0]\n",
    "\n",
    "subset = my_array[:, :, 1:3]\n",
    "\n",
    "reverse_z = my_array[::-1, :, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Also, slices are implicitly applied from left to right for unspecified dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "first_plane = my_array[0,:,:]\n",
    "\n",
    "# This is the same as first_plane\n",
    "first_plane2 = my_array[0]\n",
    "\n",
    "# A short way to get everything\n",
    "# Same as my_array[:,:,:]\n",
    "all_elements = my_array[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Masked Arrays\n",
    "\n",
    "- numpy uses a numpy array subclass called a MaskedArray.\n",
    "- MaskedArrays contain a data array and a boolean mask array (True/False).\n",
    "- Usually a fill_value is set in the data array at each location where the mask array is True.\n",
    "- Numerous ways to convert a regular numpy array to a MaskedArray:\n",
    "  - masked_equal\n",
    "  - masked_greater\n",
    "  - masked_where\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating a MaskedArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "import numpy.ma\n",
    "\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "# Now all the array elements are masked values\n",
    "my_masked = numpy.ma.masked_equal(my_array, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Your Turn!\n",
    "\n",
    "## Example 2.2: Numpy Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy.ma\n",
    "\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "print (\"my_array\")\n",
    "print (my_array)\n",
    "print (\"\\n\")\n",
    "\n",
    "# Setting an element\n",
    "my_array[1,1,1] = 10.0\n",
    "\n",
    "# Getting an element\n",
    "mid = my_array[1,1,1]\n",
    "\n",
    "print (\"Mid element set\")\n",
    "print (my_array)\n",
    "print (\"\\n\")\n",
    "\n",
    "# Getting a slice\n",
    "my_slice = my_array[1,:,:]\n",
    "\n",
    "print (\"my_slice\")\n",
    "print (my_slice)\n",
    "print (\"\\n\")\n",
    "\n",
    "# Masking the zeros\n",
    "my_masked = numpy.ma.masked_equal(my_array, 0)\n",
    "\n",
    "print (\"my_masked\")\n",
    "print (my_masked)\n",
    "print (\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---\n",
    "**NOTE**\n",
    "\n",
    "- Beginning with netcdf4-python v1.4.x, all variables returned from a NetCDF file use MaskedArrays with a default fill value set (usually 1.e+20), regardless of whether or not the data has missing values in it. \n",
    "\n",
    "- To disable this behavior, you can use the Dataset.set_always_mask(False) to return to the pre-1.4 behavior.\n",
    "\n",
    "- In some of the examples below, you might see 1.e+20 as the fill value in some of the output, and this is where it is coming from.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# xarray\n",
    "\n",
    "- xarray expands upon numpy by adding dimension names, coordinate variables, and metadata.  \n",
    "- xarray array objects (DataArray) wrap around a numpy array (NOT a numpy array subclasse).\n",
    "  - xarray **HAS A** numpy array (not an \"IS A\" relationship).\n",
    "  - Often have to extract the numpy array from the xarray array before passing it to extension modules (basemap in particular).\n",
    "  - Most numpy methods are available in xarray, but not all.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating an xarray Array From a numpy Array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import xarray\n",
    "\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "# Making up dimension names and \n",
    "# coordinates.\n",
    "my_name = \"my_xarray\"\n",
    "\n",
    "my_dims = [\"bottom_top\", \"south_north\", \"west_east\"]\n",
    "\n",
    "my_coords = {\"bottom_top\" : [100., 200., 300.],\n",
    "             \"south_north\": [40., 50., 60.],\n",
    "             \"west_east\" : [-120., -110., -100.]\n",
    "            }\n",
    "\n",
    "my_attrs = {\"info\" : \"This is my xarray\"}\n",
    "\n",
    "my_xarray = xarray.DataArray(my_array,\n",
    "                             name=my_name,\n",
    "                             dims=my_dims, \n",
    "                             coords=my_coords, \n",
    "                             attrs=my_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 2.3: Creating an xarray DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import xarray\n",
    "\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "# Making up dimension names and \n",
    "# coordinates.\n",
    "my_name = \"my_xarray\"\n",
    "\n",
    "my_dims = [\"bottom_top\", \"south_north\", \"west_east\"]\n",
    "\n",
    "my_coords = {\"bottom_top\" : [100., 200., 300.],\n",
    "          \"south_north\": [40., 50., 60.],\n",
    "          \"west_east\" : [-120., -110., -100.]\n",
    "         }\n",
    "\n",
    "my_attrs = {\"info\" : \"This is my xarray\"}\n",
    "\n",
    "my_xarray = xarray.DataArray(my_array,\n",
    "                             name=my_name,\n",
    "                             dims=my_dims, \n",
    "                             coords=my_coords, \n",
    "                             attrs=my_attrs)\n",
    "\n",
    "print (my_xarray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## xarray and Missing/Fill Data Values\n",
    "\n",
    "- xarray always uses IEEE NaN for missing data values.\n",
    "  - Can cause problems with compiled numerical routines.\n",
    "  - Can cause problems for algorithms expecting MaskedArrays.\n",
    "- wrf-python includes the fill value information in the attribute section of the metadata (_FillValue).\n",
    "- The *to_np* routine can be used to convert xarray arrays to numpy/masked arrays.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "## Example 2.4: xarray and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy.ma\n",
    "import xarray\n",
    "\n",
    "from wrf import to_np\n",
    "\n",
    "# Create a MaskedArray with 10.0 in the center\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "my_array[1,1,1] = 10.0\n",
    "\n",
    "my_masked = numpy.ma.masked_equal(my_array, 0)\n",
    "\n",
    "# Making up dimension names and \n",
    "# coordinates.\n",
    "my_name = \"my_masked_xarray\"\n",
    "\n",
    "my_dims = [\"bottom_top\", \"south_north\", \"west_east\"]\n",
    "\n",
    "my_coords = {\"bottom_top\" : [100., 200., 300.],\n",
    "          \"south_north\": [40., 50., 60.],\n",
    "          \"west_east\" : [-120., -110., -100.]\n",
    "         }\n",
    "\n",
    "my_attrs = {\"info\" : \"This is my masked xarray\",\n",
    "           \"_FillValue\" : -999.0}\n",
    "\n",
    "# Create the xarray DataArray\n",
    "my_xarray = xarray.DataArray(my_masked,\n",
    "                             name=my_name,\n",
    "                             dims=my_dims, \n",
    "                             coords=my_coords, \n",
    "                             attrs=my_attrs)\n",
    "\n",
    "print (\"xarray Array with Missing Values\")\n",
    "print (my_xarray)\n",
    "print (\"\\n\")\n",
    "\n",
    "# Covert back to a MaskedArray\n",
    "converted = to_np(my_xarray)\n",
    "\n",
    "print (\"Converted to a MaskedArray with to_np\")\n",
    "print (converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3.0 Overview of WRF Output Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The first rule of data processing:\n",
    "\n",
    "**\"ALWAYS LOOK AT YOUR DATA\"**\n",
    "\n",
    "\\- D. Shea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why Look At WRF Data? Isn't It All the Same?\n",
    "\n",
    "- WRF can be configured in various ways and can have variables turned on and off.\n",
    "- If you run in to problems, it could be due to a variable missing.  \n",
    "- Some users intentionally move the coordinate variables to a separate file to save space (not supported by NCL or wrf-python).\n",
    "- If your plot doesn't look right, there could be a map projection issue.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Viewing Tools\n",
    "There are numerous tools available to examine NetCDF data, from both outside and inside of Python.\n",
    "\n",
    "- **ncdump** (used for this example)\n",
    "- ncl_filedump\n",
    "- netcdf4-python \n",
    "- PyNIO\n",
    "- xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ncdump\n",
    "\n",
    "*ncdump* is a program included with the NetCDF libraries that can be used to examine NetCDF data.\n",
    "\n",
    "By supplying the '-h' option, only the data descriptions are returned.  Otherwise, you'll get all of the data values, which can span miles.\n",
    "\n",
    "To run:\n",
    "\n",
    "```\n",
    "$ ncdump -h wrfout_d01_2005-08-28_00:00:00\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ncdump Output\n",
    "<p></p>\n",
    "<div id=\"nc_dims\" style=\"font-size:75%;\"/>\n",
    "\n",
    "``` \n",
    "netcdf wrfout_d01_2005-08-28_00\\:00\\:00 {\n",
    "dimensions:\n",
    "    Time = UNLIMITED ; // (4 currently)\n",
    "    \n",
    "    DateStrLen = 19 ;\n",
    "    \n",
    "    west_east = 90 ;\n",
    "    \n",
    "    south_north = 73 ;\n",
    "    \n",
    "    bottom_top = 29 ;\n",
    "    \n",
    "    bottom_top_stag = 30 ;\n",
    "    \n",
    "    soil_layers_stag = 4 ;\n",
    "    \n",
    "    west_east_stag = 91 ;\n",
    "    \n",
    "    south_north_stag = 74 ;\n",
    "    \n",
    "```\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ncdump Output\n",
    "<p></p>\n",
    "<div id=\"nc_vars\" style=\"font-size:75%;\">\n",
    "    \n",
    "```\n",
    "variables:\n",
    "    char Times(Time, DateStrLen) ;\n",
    "    float XLAT(Time, south_north, west_east) ;\n",
    "        XLAT:FieldType = 104 ;\n",
    "        XLAT:MemoryOrder = \"XY \" ;\n",
    "        XLAT:description = \"LATITUDE, SOUTH IS NEGATIVE\" ;\n",
    "        XLAT:units = \"degree_north\" ;\n",
    "        XLAT:stagger = \"\" ;\n",
    "        XLAT:coordinates = \"XLONG XLAT\" ;\n",
    "    float XLONG(Time, south_north, west_east) ;\n",
    "        XLONG:FieldType = 104 ;\n",
    "        XLONG:MemoryOrder = \"XY \" ;\n",
    "        XLONG:description = \"LONGITUDE, WEST IS NEGATIVE\" ;\n",
    "        XLONG:units = \"degree_east\" ;\n",
    "        XLONG:stagger = \"\" ;\n",
    "        XLONG:coordinates = \"XLONG XLAT\" ;\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "    float SST_INPUT(Time, south_north, west_east) ;\n",
    "        SST_INPUT:FieldType = 104 ;\n",
    "        SST_INPUT:MemoryOrder = \"XY \" ;\n",
    "        SST_INPUT:description = \"SEA SURFACE TEMPERATURE \n",
    "            FROM WRFLOWINPUT FILE\" ;\n",
    "        SST_INPUT:units = \"K\" ;\n",
    "        SST_INPUT:stagger = \"\" ;\n",
    "        SST_INPUT:coordinates = \"XLONG XLAT XTIME\" ;\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ncdump Output\n",
    "<p></p>\n",
    "<div id=\"nc_attrs\" style=\"font-size:75%;\">\n",
    "    \n",
    "```\n",
    "// global attributes:\n",
    "        :TITLE = \" OUTPUT FROM WRF V3.7 MODEL\" ;\n",
    "        :START_DATE = \"2005-08-28_00:00:00\" ;\n",
    "        :SIMULATION_START_DATE = \"2005-08-28_00:00:00\" ;\n",
    "        :WEST-EAST_GRID_DIMENSION = 91 ;\n",
    "        :SOUTH-NORTH_GRID_DIMENSION = 74 ;\n",
    "        :BOTTOM-TOP_GRID_DIMENSION = 30 ;\n",
    "        :DX = 30000.f ;\n",
    "        :DY = 30000.f ;\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        :CEN_LAT = 28.00002f ;\n",
    "        :CEN_LON = -89.f ;\n",
    "        :TRUELAT1 = 30.f ;\n",
    "        :TRUELAT2 = 60.f ;\n",
    "        :MOAD_CEN_LAT = 28.00002f ;\n",
    "        :STAND_LON = -89.f ;\n",
    "        :POLE_LAT = 90.f ;\n",
    "        :POLE_LON = 0.f ;\n",
    "        :GMT = 0.f ;\n",
    "        :JULYR = 2005 ;\n",
    "        :JULDAY = 240 ;\n",
    "        :MAP_PROJ = 1 ;\n",
    "        :MAP_PROJ_CHAR = \"Lambert Conformal\" ;\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "}\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dimensions\n",
    "\n",
    "WRF-ARW uses an Arakawa C-grid staggered grid [(taken from mmm website)] [1]\n",
    "\n",
    "- Mass related quantities (pressure, temperature, etc) are computed at the center of a grid cell. \n",
    "- The u-component of the horizontal wind is calculated at the left and right edges of a grid cell.  It has one more \n",
    "  point in the x direction than the mass grid.\n",
    "- The v-component of the horizontal wind is calculated at the bottom and top edges of a grid cell.  It has one more     point in the y direction than the mass grid. \n",
    "- The corners of each grid box are know as the 'staggered' grid, and it has one additional point in both the x and y direction.\n",
    "\n",
    "[1]: http://www2.mmm.ucar.edu/rt/amps/information/configuration/wrf_grid_structure.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![alt](images/wrf_stagger.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## WRF File Dimensions\n",
    "<p>\n",
    "<div id=\"nc_dims\" style=\"font-size:75%;\"/>\n",
    "\n",
    "``` \n",
    "netcdf wrfout_d01_2005-08-28_00\\:00\\:00 {\n",
    "dimensions:\n",
    "    Time = UNLIMITED ; // (4 currently)\n",
    "    \n",
    "    DateStrLen = 19 ;\n",
    "    \n",
    "    west_east = 90 ;\n",
    "    \n",
    "    south_north = 73 ;\n",
    "    \n",
    "    bottom_top = 29 ;\n",
    "    \n",
    "    bottom_top_stag = 30 ; <-- Extra grid point\n",
    "    \n",
    "    soil_layers_stag = 4 ;\n",
    "    \n",
    "    west_east_stag = 91 ; <-- Extra grid point\n",
    "    \n",
    "    south_north_stag = 74 ; <-- Extra grid point\n",
    "    \n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Variables\n",
    "\n",
    "- Each variable is made up of dimensions, attributes, and data values. \n",
    "- Pay special attention to the units and coordinates attribute.\n",
    "  - The *coordinates* attribute specifies the variables that contain the latitude and longitude \n",
    "    information for each grid box (XLONG, XLAT).\n",
    "  - More recent versions of WRF include an XTIME coordinate.\n",
    "  - The coordinates are named with Fortran ordering, so they'll be listed in reverse.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## WRF File Variable\n",
    "<p>\n",
    "<div id=\"var_example\" style=\"font-size:75%;\"/>\n",
    "\n",
    "```\n",
    "float P(Time, bottom_top, south_north, west_east) ; <- Dims\n",
    "\tP:FieldType = 104 ;                       <-  Attribute\n",
    "\tP:MemoryOrder = \"XYZ\" ;                   <-  Attribute\n",
    "    P:description = \"perturbation pressure\" ; <-  Attribute\n",
    "\tP:units = \"Pa\" ;                          <-  Attribute\n",
    "    P:stagger = \"\" ;                          <-  Attribute\n",
    "\tP:coordinates = \"XLONG XLAT XTIME\" ;      <-  Attribute\n",
    "    \n",
    "data:\n",
    "\n",
    " P =\n",
    "  339.8281, 340.3281, 340.25, 341.4531, ... \n",
    "    355.8672, 356.9531, 361.2578, 365.7188,  ...\n",
    "\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Global Attributes\n",
    "\n",
    "- Provide a description of how the model was set up (resolution, map projection, microphysics, etc)\n",
    "- For plotting, the map projection parameters will be the most important.\n",
    "- wrf-python uses this information to build the mapping object in your plotting system of choice - basemap, cartopy, pyngl.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## WRF Global Attributes\n",
    "<p>\n",
    "<div id=\"proj_stuff\" style=\"font-size:75%;\"/>\n",
    "\n",
    "```\n",
    ".\n",
    ".\n",
    ".\n",
    ":CEN_LAT = 28.00002f ;\n",
    ":CEN_LON = -89.f ;\n",
    ":TRUELAT1 = 30.f ;\n",
    ":TRUELAT2 = 60.f ;\n",
    ":MOAD_CEN_LAT = 28.00002f ;\n",
    ":STAND_LON = -89.f ;\n",
    ":POLE_LAT = 90.f ;\n",
    ":POLE_LON = 0.f ;\n",
    ".\n",
    ".\n",
    ":MAP_PROJ = 1 ;\n",
    ":MAP_PROJ_CHAR = \"Lambert Conformal\" ;\n",
    ".\n",
    ".\n",
    ".\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 3.1: Running ncdump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "# This simply executes 'ncdump -h {wrf_file}' \n",
    "# from Python\n",
    "p = Popen([\"ncdump\", \"-h\", \"{}\".format(file_path)], \n",
    "          stdout=PIPE, stderr=STDOUT)\n",
    "output, _ = p.communicate()\n",
    "\n",
    "print(output.decode())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Reading a WRF File in Python\n",
    "\n",
    "You have several options to read a WRF NetCDF file in Python. \n",
    "\n",
    "- **netcdf4-python**\n",
    "- PyNIO\n",
    "- xarray (xarray.Dataset type not currently supported in wrf-python)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## netcdf4-python Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "file_path = \"/Users/ladwig/wrf_tutorial_data/wrfout_d01_2010-06-02_00_00_00\"\n",
    "\n",
    "wrf_file = Dataset(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 3.2: Using netcdf4-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "print(wrf_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Getting Variables and Attributes\n",
    "\n",
    "- netcdf4-python uses an old API that was \n",
    "  originally created for a package called \n",
    "  Scientific.IO.NetCDF.\n",
    "\n",
    "- PyNIO and SciPy also use this API.\n",
    "\n",
    "- xarray does not use this API.\n",
    "\n",
    "- The API may look a little dated.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Getting Global Attributes\n",
    "\n",
    "The get the full dictionary of global attributes, use the \\_\\_dict\\_\\_ attribute.  \n",
    "\n",
    "To work with one attribute at a time, you can use the getncattr and setncattr methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_attrs = wrf_file.__dict__\n",
    "\n",
    "# To get the value for MAP_PROJ, you can do:\n",
    "map_proj = wrf_file.__dict__[\"MAP_PROJ\"]\n",
    "\n",
    "# Or more cleanly\n",
    "map_proj = wrf_file.getncattr(\"MAP_PROJ\")\n",
    "\n",
    "# Or for those that know __dict__ is where the class members are stored\n",
    "map_proj = wrf_file.MAP_PROJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Getting Variables, Variable Attributes, and Variable Data\n",
    "\n",
    "All variables are stored in a dictionary attribute called *variables*.  \n",
    "\n",
    "Let's get the perturbation pressure \"P\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return a netCDF4.Variable object\n",
    "p = wrf_file.variables[\"P\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To get the variable attributes, you can use the \\_\\_dict\\_\\_ attribute to get a dictionary of all attributes. \n",
    "\n",
    "Use the *getncattr* function if you already know the attribute name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a dictionary of all of P's \n",
    "# attributes\n",
    "p_attrs = p.__dict__\n",
    "\n",
    "# Let's just get the 'coordinates' attribute\n",
    "p_coords = p.getncattr(\"coordinates\")\n",
    "\n",
    "# Or using the class attribute directly\n",
    "p_coords = p.coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To get the variable's data as a numpy array, you need to use Python's bracket \"[ ]\" syntax.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a numpy array for all times\n",
    "p_all_data = p[:,:,:,:]\n",
    "\n",
    "# A shorthand version of the above.\n",
    "p_all_data = p[:]\n",
    "\n",
    "# This will extract the numpy array for \n",
    "# time index 0.\n",
    "p_t0_data = p[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 3.3: Variables, Attributes, and Data with netcd4-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "# Create the netCDF4.Dataset object\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Get the global attribute dict\n",
    "global_attrs = wrf_file.__dict__\n",
    "print (\"Global attributes for the file\")\n",
    "print(global_attrs)\n",
    "print (\"\\n\")\n",
    "\n",
    "# Just get the 'MAP_PROJ' attribute\n",
    "map_proj = wrf_file.getncattr(\"MAP_PROJ\")\n",
    "print (\"The MAP_PROJ attribute:\")\n",
    "print (map_proj)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Get the perturbation pressure variable\n",
    "p = wrf_file.variables[\"P\"]\n",
    "print (\"The P variable: \")\n",
    "print(p)\n",
    "print (\"\\n\")\n",
    "\n",
    "# Get the P attributes\n",
    "p_attrs = p.__dict__\n",
    "print (\"The attribute dict for P\")\n",
    "print (p_attrs)\n",
    "print (\"\\n\")\n",
    "\n",
    "# Get the 'coordinates' attribute for P\n",
    "coords = p.getncattr(\"coordinates\")\n",
    "print (\"Coordinates for P:\")\n",
    "print (coords)\n",
    "print (\"\\n\")\n",
    "\n",
    "# Get the P numpy array for all times\n",
    "p_all_data = p[:]\n",
    "print (\"The P numpy array: \")\n",
    "print (p_all_data)\n",
    "print (\"\\n\")\n",
    "\n",
    "# Get the P numpy array for time 0\n",
    "p_t0_data = p[0,:]\n",
    "print (\"P array at time 0:\")\n",
    "print (p_t0_data)\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pop Quiz\n",
    "\n",
    "What is the first rule of data processing?\n",
    "\n",
    "    A) YOU DO NOT TALK ABOUT DATA PROCESSING\n",
    "    B) 60% OF THE TIME, IT WORKS EVERY TIME\n",
    "    C) ALWAYS LOOK AT YOUR DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4.0 WRF-Python Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "WRF-Python provides functionality similar to what is found in the NCL-WRF package:\n",
    "\n",
    "- Over 30 diagnostics calculations.\n",
    "- Several interpolation routines (horizontal level, vertical cross section, horizontal \"surface\").\n",
    "- Plot helper utilities for cartopy, basemap, and PyNGL.\n",
    "- WRF-ARW only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The most commonly used functions:\n",
    "\n",
    "- **getvar**: Extracts variables and diagnostic variables.\n",
    "- **interplevel**: Linearly interpolates a 3D variable to a horizontal plane at a specified vertical level.\n",
    "- **vertcross**: Interpolates a 3D variable to a vertical cross section.\n",
    "- **vinterp**: Interpolates a 3D variable to a new surface (e.g. theta-e)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The getvar function\n",
    "\n",
    "The *getvar* function can be used to:\n",
    "\n",
    "- Extract NetCDF variables from a file, similar to netcdf4-python or PyNIO.\n",
    "- Compute diagnostic variables.\n",
    "- Concatenate a variable (either NetCDF or diagnostic) across multiple files. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Getting the NetCDF HGT Variable with getvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar\n",
    "\n",
    "file_path = \"/Users/ladwig/wrf_tutorial_data/wrfout_d01_2010-06-02_00_00_00\"\n",
    "\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "hgt = getvar(wrf_file, \"HGT\", timeidx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 4.1: Using getvar to Extract a WRF NetCDF Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "hgt = getvar(wrf_file, \"HGT\", timeidx=0)\n",
    "\n",
    "print(hgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Computing a Diagnostic Variable with getvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we're going to compute sea level pressure.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar\n",
    "\n",
    "file_path = \"/Users/ladwig/wrf_tutorial_data/wrfout_d01_2010-06-02_00_00_00\"\n",
    "\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "slp = getvar(wrf_file, \"slp\", timeidx=0, units=\"hPa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the *units* keyword argument.  Some diagnostics support several choices for units.  However, unit support is still relatively primitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 4.2: Using getvar to compute Sea Level Pressure (SLP)\n",
    "\n",
    "Also try changing the units for by specifiying the following values:  'hPa', 'Pa', 'atm', 'mmhg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "slp = getvar(wrf_file, \"slp\", timeidx=0, units=\"mmhg\")\n",
    "\n",
    "print(slp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Combining Across Multiple Files\n",
    "\n",
    "WRF-Python has two methods for combining a variable across multiple files:\n",
    "- **cat** - combines the the variable along the Time dimension (Note: you must order the files yourself)\n",
    "- **join** - creates a new left-most dimension for each file\n",
    "\n",
    "To extract all times in to a single array, set *timeidx* to wrf.ALL_TIMES (an alias for None).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this example, we're using the 'cat' method, which is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, ALL_TIMES\n",
    "\n",
    "file_paths = [\"/Users/ladwig/wrf_tutorial_data/wrfout_d01_2010-06-02_00_00_00\",\n",
    "              \"/Users/ladwig/wrf_tutorial_data/wrfout_d01_2010-06-03_00_00_00\"\n",
    "             ]\n",
    "\n",
    "wrf_files = [Dataset(file_paths[0]), Dataset(file_paths[1])]\n",
    "\n",
    "# Explicitly specifying 'cat', but this is the default\n",
    "slp = getvar(wrf_files, \"slp\", timeidx=ALL_TIMES, method=\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Example 4.3: Combining Files Using the 'cat' Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, ALL_TIMES\n",
    "\n",
    "file_paths = multiple_wrf_files()\n",
    "\n",
    "wrf_files = [Dataset(f) for f in file_paths]\n",
    "\n",
    "slp = getvar(wrf_files, \"slp\", timeidx=ALL_TIMES, method=\"cat\")\n",
    "\n",
    "print (slp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 4.4: Combining Files Using the 'join' Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, ALL_TIMES\n",
    "\n",
    "file_paths = multiple_wrf_files()\n",
    "\n",
    "wrf_files = [Dataset(f) for f in file_paths]\n",
    "\n",
    "slp = getvar(wrf_files, \"slp\", timeidx=ALL_TIMES, method=\"join\")\n",
    "\n",
    "print(slp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interpolation Routines\n",
    "\n",
    "- **interplevel** - linear interpolation to a horizontal plane at a specified height or pressure level.\n",
    "- **vertcross** - vertical cross section interpolation to a vertical plane through two specified points \n",
    "  (or a pivot point and angle).\n",
    "- **vinterp** - interpolates to a \"surface\", which could be pressure levels or temperature levels like theta-e. A smarter version of *interplevel*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The interplevel function\n",
    "\n",
    "- The easiest way to get a field at a specified height or pressure vertical level (500 mb, 5000 m, etc).\n",
    "- Uses linear interpolation, which is fast and generally good enough for plotting.\n",
    "- You should use *vinterp* for geopotential height if you want more accuracy, since the interpolation is done with the decaying exponential \n",
    "  pressure profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### interplevel Example\n",
    " \n",
    "Let's get the 500 hPa geopotential height in decameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, interplevel\n",
    "\n",
    "file_path = \"/Users/ladwig/wrf_tutorial_data/wrfout_d01_2010-06-02_00_00_00\"\n",
    "\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "pres = getvar(wrf_file, \"pressure\", timeidx=0)\n",
    "\n",
    "ht = getvar(wrf_file, \"z\", timeidx=0, units=\"dm\")\n",
    "\n",
    "ht_500 = interplevel(ht, pres, 500.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 4.5: Interpolate to 500 hPa Using interplevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, interplevel\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "pres = getvar(wrf_file, \"pressure\", timeidx=0)\n",
    "ht = getvar(wrf_file, \"z\", timeidx=0, units=\"dm\")\n",
    "\n",
    "ht_500 = interplevel(ht, pres, 500.0)\n",
    "\n",
    "print (ht_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The vertcross function\n",
    "\n",
    "The idea is to draw a horizontal line at the surface, and the cross section is defined as a vertical plane extending up from this line.\n",
    "\n",
    "- The new x-axis for a cross section plot is the points along the line you made.  The line can be defined by:\n",
    "  1. defining a start point and an end point by using (x,y) grid coordinates or (latitude, longitude) coordinates.\n",
    "  2. defining a pivot point and an angle, which is useful for cross sections that will span most of the domain.\n",
    "- The new y-axis will be a set of vertical levels at default intervals (1% increments), or you can choose them yourself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Introducing the CoordPair Class\n",
    "\n",
    "A *CoordPair* is simply used to store (x,y) coordinates, or (lat,lon) coordinates.  It is also possible to have (x, y, lat, lon), but that's mostly used for metadata.  \n",
    "\n",
    "The *CoordPair* will be used to define your cross section line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrf import CoordPair\n",
    "\n",
    "# Creating an x,y pair\n",
    "x_y_pair = CoordPair(x=10, y=20)\n",
    "\n",
    "# Creating a lat,lon pair\n",
    "lat_lon_pair = CoordPair(lat=30.0, lon=-120.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### vertcross Example\n",
    "\n",
    "In this example, we're going to define the cross section using a start point and and end point.  \n",
    "\n",
    "We're going to let the algorithm pick the levels, which are at ~1% increments by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, vertcross, CoordPair\n",
    "\n",
    "file_path = \"/Users/ladwig/wrf_tutorial_data/wrfout_d01_2010-06-02_00_00_00\"\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Making a diagonal cross section line from \n",
    "# bottom left to top right.\n",
    "bottom_left = CoordPair(x=0, y=0)\n",
    "top_right = CoordPair(x=-1, y=-1)\n",
    "\n",
    "# Let's get wind speed in kts\n",
    "wspd_wdir = getvar(wrf_file, \"wspd_wdir\", timeidx=0, units=\"kt\")           \n",
    "wspd = wspd_wdir[0,:]\n",
    "\n",
    "# Get the height levels\n",
    "ht = getvar(wrf_file, \"z\", timeidx=0)\n",
    "\n",
    "# Compute the wind speed cross section\n",
    "wspd_cross = vertcross(wspd, ht, start_point=bottom_left, end_point=top_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 4.6: Interpolate to a Vertical Cross Section with vertcross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, vertcross, CoordPair\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Making a diagonal cross section line from \n",
    "# bottom left to top right.\n",
    "bottom_left = CoordPair(x=0, y=0)\n",
    "top_right = CoordPair(x=-1, y=-1)\n",
    "\n",
    "# Let's get wind speed in kts\n",
    "wspd_wdir = getvar(wrf_file, \"wspd_wdir\", timeidx=0, units=\"kt\")\n",
    "wspd = wspd_wdir[0,:]\n",
    "\n",
    "# Get the height levels\n",
    "ht = getvar(wrf_file, \"z\", timeidx=0)\n",
    "\n",
    "wspd_cross = vertcross(wspd, ht, start_point=bottom_left, end_point=top_right)\n",
    "\n",
    "print (wspd_cross)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The vinterp function\n",
    "\n",
    "- Used for interpolating a field to a type of surface:\n",
    "  - pressure\n",
    "  - geopotential height\n",
    "  - theta\n",
    "  - theta-e\n",
    "- User must specify the interpolation level(s) on the new surface.\n",
    "- A smarter, albeit slower and more complicated, version of *interplevel*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### vinterp Example\n",
    "\n",
    "In this example, we're going to interpolate pressure to theta-e levels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, vinterp \n",
    "\n",
    "file_path = \"/Users/ladwig/wrf_tutorial_data/wrfout_d01_2010-06-02_00_00_00\"\n",
    "wrf_file = Dataset(file_path) \n",
    "\n",
    "pres = getvar(wrf_file, \"pressure\", timeidx=0)\n",
    "\n",
    "# Interpolate pressure to theta-e levels         \n",
    "interp_levels = [280, 285, 290, 292, 294, \n",
    "                 296, 298, 300, 305, 310]\n",
    "\n",
    "pres_eth = vinterp(wrf_file, \n",
    "                   field=pres, \n",
    "                   vert_coord=\"theta-e\", \n",
    "                   interp_levels=interp_levels, \n",
    "                   extrapolate=False, \n",
    "                   field_type=\"pressure\", \n",
    "                   log_p=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 4.7: Interpolate to Theta-e Levels with vinterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, vinterp \n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path) \n",
    "\n",
    "pres = getvar(wrf_file, \"pressure\", timeidx=0)\n",
    "\n",
    "# Interpolate pressure to theta-e levels         \n",
    "interp_levels = [280., 285., 290., 292., 294., \n",
    "                 296., 298., 300., 305., 310.]\n",
    "\n",
    "pres_eth = vinterp(wrf_file, \n",
    "                   field=pres, \n",
    "                   vert_coord=\"theta-e\", \n",
    "                   interp_levels=interp_levels, \n",
    "                   extrapolate=True, \n",
    "                   field_type=\"pressure\", \n",
    "                   log_p=False,\n",
    "                   timeidx=0)\n",
    "\n",
    "print(pres_eth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Other Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## *to_np*\n",
    "\n",
    "Converts an *xarray.DataArray* to a numpy array.\n",
    "\n",
    "This is often necessary when passing wrf-python variables to the plotting functions or to a compiled extension module.\n",
    "\n",
    "This routine does the following:\n",
    "\n",
    "- If no missing/fill values, then it simply calls the *xarray.DataArray.values* property.\n",
    "- If missing/fill values are present, then it replaces the NaN values with the fill value found in the attributes, and returns a MaskedArray.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### to_np Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, to_np \n",
    "\n",
    "file_path = \"/Users/ladwig/wrf_tutorial_data/wrfout_d01_2010-06-02_00_00_00\"\n",
    "wrf_file = Dataset(file_path) \n",
    "\n",
    "pres_xarray = getvar(wrf_file, \"pressure\", timeidx=0)\n",
    "\n",
    "pres_numpy = to_np(pres_xarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## xy_to_ll and ll_to_xy\n",
    "\n",
    "These routines convert to/from grid (x,y) coordinates to/from (lat,lon) coordinates. \n",
    "\n",
    "Works with a single point or sequences of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### xy_to_ll and ll_to_xy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, xy_to_ll, ll_to_xy \n",
    "\n",
    "file_path = \"/Users/ladwig/wrf_tutorial_data/wrfout_d01_2010-06-02_00_00_00\"\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Convert (x=20,y=50) and (x=30,y=75) to latitude,longitude\n",
    "lat_lon = xy_to_ll(wrf_file, [20,30], [50,75])\n",
    "\n",
    "# Convert back to x,y\n",
    "x_y = ll_to_xy(wrf_file, lat_lon[0,:], lat_lon[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 4.8: xy_to_ll and ll_to_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, xy_to_ll, ll_to_xy \n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "lat_lon = xy_to_ll(wrf_file, [20, 30], [50, 75])\n",
    "\n",
    "print(\"lat,lon values\")\n",
    "print(lat_lon)\n",
    "print(\"\\n\")\n",
    "\n",
    "x_y = ll_to_xy(wrf_file, lat_lon[0,:], lat_lon[1,:])\n",
    "\n",
    "print(\"x,y values\")\n",
    "print(x_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5.0 Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Plotting\n",
    "- Plotting wrf-python variables in Python can be done using either matplotlib or PyNGL.\n",
    "\n",
    "- For this tutorial, we're going to focus on matplotlib (using cartopy for the mapping).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Extremely Brief Overview of Matplotlib\n",
    "\n",
    "- Under the hood, matplotlib uses an object oriented API.\n",
    "\n",
    "- In simplest terms, a matplotlib plot consists of Figure object that contains an Axes object (or multiple Axes objects).\n",
    "\n",
    "- The Axes object is where the action is.\n",
    "\n",
    "- The Axes object contains the methods for contouring, making histograms, adding colorbar, etc.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The pyplot API\n",
    "\n",
    "- Most matplotlib users do no need to know much about the underlying object oriented API.\n",
    "\n",
    "- Matplotlib includes a series of standalone functions that wrap around the object oriented API.\n",
    "\n",
    "- These standalone functions are in the matplotlib.pyplot package and it was designed to look similar to the Matlab API.\n",
    "\n",
    "- New users should start here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 5.1: Single Wind Barb Example with pyplot\n",
    "\n",
    "In this example, we are going to plot a single wind barb in the center of the domain using the pyplot API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "# Make a 5x5 grid of missing u,v values\n",
    "u = np.ma.masked_equal(np.zeros((5,5)), 0)\n",
    "v = np.ma.masked_equal(np.zeros((5,5)), 0)\n",
    "\n",
    "# Add u,v winds to center of domain\n",
    "u[2,2] = 10.0\n",
    "v[2,2] = 10.0\n",
    "\n",
    "# Draw a single wind barb in the middle using pyplot API\n",
    "# Note:  the axes objects are \"hidden\" in these functions\n",
    "fig = pyplot.figure()\n",
    "pyplot.barbs(u, v)\n",
    "\n",
    "# Set the x and y ranges so the barb is in the middle\n",
    "pyplot.xlim(0, 4)\n",
    "pyplot.ylim(0, 4)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mixing the APIs\n",
    "\n",
    "- Often you will find yourself mixing the object oriented API with the pyplot API.  \n",
    "\n",
    "- This is required when making subplots, but that is beyond the scope of this tutorial.  \n",
    "\n",
    "- The next example shows how to make the single wind barb using the axes object directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 5.2: Single Wind Barb Using the Axes Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "# Make a 5x5 grid of missing u,v values\n",
    "u = np.ma.masked_equal(np.zeros((5,5)), 0)\n",
    "v = np.ma.masked_equal(np.zeros((5,5)), 0)\n",
    "\n",
    "# Add u,v winds to center of domain\n",
    "u[2,2] = 10.0\n",
    "v[2,2] = 10.0\n",
    "\n",
    "# We'll use pyplot to create the figure and \n",
    "# get the axes\n",
    "fig = pyplot.figure()\n",
    "ax = pyplot.axes() # <- Now we're using the Axes object directly\n",
    "\n",
    "# Now use the axes directly to create the barbs\n",
    "ax.barbs(u, v)\n",
    "\n",
    "# Set the x and y ranges using the axes directly\n",
    "ax.set_xlim(0, 4)\n",
    "ax.set_ylim(0, 4)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## WRF-Python Plotting Helper Functions\n",
    "\n",
    "WRF-Python has several functions to help with plotting when using cartopy, basemap, or PyNGL.  \n",
    "\n",
    "- **get_cartopy, get_basemap, get_pyngl**: Returns the mapping object used by the plotting system.\n",
    "- **latlon_coords**: Returns the latitude and longitude coordinate variables.\n",
    "- **get_bounds**: Returns the geographic boundaries for the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Plotting with cartopy\n",
    "\n",
    "Cartopy uses the same API as matplotlib by returning a matplotlib.axes.Axes subclass (cartopy.mpl.geoaxes.GeoAxes) when a *projection* keyword argument is passed to the matplotlib.pyplot.axes function.  \n",
    "\n",
    "### Getting the GeoAxes object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "import cartopy.crs\n",
    "\n",
    "# Create a lat/lon map projection object.\n",
    "latlon = cartopy.crs.PlateCarree()\n",
    "\n",
    "geo_axes = pyplot.axes(projection=latlon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Getting the cartopy Projection Object and Lat/Lon Coordinates Using WRF-Python\n",
    "\n",
    "- When xarray is installed and enabled, wrf-python carries the projection information around in the metadata of a variable.  \n",
    "\n",
    "- You can use the *get_cartopy* function to extract the cartopy projection object from a variable. \n",
    "\n",
    "- You can use the *latlon_coords* function to get the latitude and longitude points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, get_cartopy, latlon_coords)\n",
    "\n",
    "file_path = \"/Users/ladwig/wrf_tutorial_data/wrfout_d01_2010-06-02_00_00_00\"\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "terrain = getvar(wrf_file, \"ter\", timeidx=0)\n",
    "\n",
    "cart_proj = get_cartopy(terrain)\n",
    "lats, lons = latlon_coords(terrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 5.3: Making a Plot of Terrain\n",
    "\n",
    "Let's make a plot of terrain.  It's the easiest way to check if your map is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, to_np, get_cartopy, latlon_coords\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Get the terrain height\n",
    "terrain = getvar(wrf_file, \"ter\", timeidx=0)\n",
    "\n",
    "# Get the cartopy object and the lat,lon coords\n",
    "cart_proj = get_cartopy(terrain)\n",
    "lats, lons = latlon_coords(terrain)\n",
    "\n",
    "# Create a figure and get the GetAxes object\n",
    "fig = pyplot.figure(figsize=(9, 10))\n",
    "geo_axes = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and add the states.\n",
    "# See the cartopy documentation for more on this.\n",
    "states = NaturalEarthFeature(category='cultural', \n",
    "                             scale='50m', \n",
    "                             facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "geo_axes.add_feature(states, linewidth=2.0, edgecolor='white', zorder=2)\n",
    "\n",
    "# Set the contour levels\n",
    "levels = np.arange(250., 4000., 500.)\n",
    "\n",
    "# Make the contour lines and fill them.\n",
    "pyplot.contour(to_np(lons), to_np(lats), \n",
    "               to_np(terrain), levels=levels, \n",
    "               colors=\"black\",\n",
    "               transform=crs.PlateCarree())\n",
    "pyplot.contourf(to_np(lons), to_np(lats), \n",
    "                to_np(terrain), levels=levels,\n",
    "                transform=crs.PlateCarree(),\n",
    "                cmap=get_cmap(\"terrain\"))\n",
    "             \n",
    "# Add a color bar. The shrink often needs to be set \n",
    "# by trial and error.\n",
    "pyplot.colorbar(ax=geo_axes, shrink=1.0)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cropping\n",
    "\n",
    "Sometimes WRF domains are much larger than what you care about.\n",
    "\n",
    "Plots can be cropped in two ways using wrf-python:\n",
    "\n",
    "1. Crop the data before plotting.\n",
    "  - Less data to process = faster!\n",
    "  - There's a slight risk of issues at borders, \n",
    "    but matplotlib seems pretty smart about this.\n",
    "2. Crop the domain with matplotlib using x,y axis limits.\n",
    "  - Runs slower since all of the domain is contoured.\n",
    "  - Should always be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Method 1: Cropping then Plotting\n",
    "\n",
    "If you are cropping the data, then cartopy should just work without worrying about setting the axis limits, as long as xarray is installed and enabled.\n",
    "\n",
    "**Let's start by taking a quick look at the full plot of precipitable water.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 5.4: Full Plot of Precipitable Water (inches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, to_np, get_cartopy, latlon_coords\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Get precipitable water in kg/m2 [or mm]\n",
    "pw = getvar(wrf_file, \"pw\", 0)\n",
    "\n",
    "# Get the Precipitable Water in inches \n",
    "# [Note: 1 kg/m2 = 1 mm = .0393701 in]\n",
    "pw_in = pw * .0393701\n",
    "\n",
    "# After a math operation, xarray drops the attributes, so \n",
    "# let's add them back and set the units to be inches\n",
    "pw_in.attrs.update(pw.attrs)\n",
    "pw_in.attrs[\"units\"] = \"in\"\n",
    "\n",
    "\n",
    "# Get the cartopy object and the lat,lon coords\n",
    "cart_proj = get_cartopy(pw_in)\n",
    "lats, lons = latlon_coords(pw_in)\n",
    "\n",
    "# Create a figure and get the GetAxes object\n",
    "fig = pyplot.figure(figsize=(9, 10))\n",
    "geo_axes = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and add the states\n",
    "# See the cartopy documentation for more on this\n",
    "states = NaturalEarthFeature(category='cultural', \n",
    "                             scale='50m', \n",
    "                             facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "geo_axes.add_feature(states, linewidth=2.0, edgecolor='black', zorder=2)\n",
    "\n",
    "# Set the contour levels so that all plots match\n",
    "levels = np.arange(0, 1.4, .2)\n",
    "\n",
    "# Make the contour lines and fill them.\n",
    "pyplot.contour(to_np(lons), to_np(lats), \n",
    "               to_np(pw_in), levels=levels, colors=\"black\",\n",
    "               transform=crs.PlateCarree())\n",
    "pyplot.contourf(to_np(lons), to_np(lats), \n",
    "                to_np(pw_in), levels=levels, \n",
    "                transform=crs.PlateCarree(),\n",
    "                cmap=get_cmap(\"jet\"))\n",
    "             \n",
    "# Add a color bar. The shrink often needs to be set \n",
    "# by trial and error.\n",
    "pyplot.colorbar(ax=geo_axes, shrink=1.0)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 5.5: Cropping by Slicing the Data\n",
    "\n",
    "Let's crop the data to the lower right quadrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, to_np, get_cartopy, latlon_coords\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Get precipitable water in kg/m2 [or mm]\n",
    "pw = getvar(wrf_file, \"pw\")\n",
    "\n",
    "# Get the Precipitable Water in inches \n",
    "# [Note: 1 kg/m2 = 1 mm = .0393701 in]\n",
    "pw_in = pw * .0393701\n",
    "\n",
    "# After a math operation, xarray drops the attributes, so \n",
    "# let's add them back and set the units to be inches\n",
    "pw_in.attrs.update(pw.attrs)\n",
    "pw_in.attrs[\"units\"] = \"in\"\n",
    "\n",
    "# Determine the center of the domain in grid coordinates\n",
    "pw_shape = pw_in.shape\n",
    "center_y = int(pw_shape[-2]/2.) - 1\n",
    "center_x = int(pw_shape[-1]/2.) - 1\n",
    "\n",
    "# Slice from bottom to middle for y\n",
    "# Slice from middle to right for x\n",
    "pw_quad = pw_in[..., 0:center_y+1, center_x:]\n",
    "\n",
    "# Get the cartopy object and the lat,lon coords\n",
    "cart_proj = get_cartopy(pw_quad)\n",
    "lats, lons = latlon_coords(pw_quad)\n",
    "\n",
    "# Create a figure and get the GetAxes object\n",
    "fig = pyplot.figure(figsize=(9, 10))\n",
    "geo_axes = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and add the states\n",
    "# See the cartopy documentation for more on this.\n",
    "states = NaturalEarthFeature(category='cultural', \n",
    "                             scale='50m', \n",
    "                             facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "geo_axes.add_feature(states, linewidth=2.0, edgecolor='black', zorder=2)\n",
    "\n",
    "# Set the contour levels\n",
    "levels = np.arange(0, 1.4, .2)\n",
    "\n",
    "# Make the contour lines and fill them.\n",
    "pyplot.contour(to_np(lons), to_np(lats), \n",
    "               to_np(pw_quad), levels=levels, colors=\"black\",\n",
    "               transform=crs.PlateCarree())\n",
    "pyplot.contourf(to_np(lons), to_np(lats), \n",
    "                to_np(pw_quad), levels=levels, \n",
    "                transform=crs.PlateCarree(),\n",
    "                cmap=get_cmap(\"jet\"))\n",
    "             \n",
    "# Add a color bar. The shrink often needs to be set \n",
    "# by trial and error.\n",
    "pyplot.colorbar(ax=geo_axes, shrink=1.0)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Method 2: Cropping by Setting x and y Extents\n",
    "\n",
    "This time, let's crop the domain by using the x and y extents in matplotlib.\n",
    "\n",
    "Also, we're going to crop the domain using lat,lon geographic boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Introducing the GeoBounds class\n",
    "\n",
    "To create geographic boundaries, you \n",
    "supply a GeoBounds object constructed with \n",
    "set of bottom_left and top_right CoordPair objects.\n",
    "\n",
    "The CoordPair objects need to use the *lat* \n",
    "and *lon* arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrf import CoordPair, GeoBounds\n",
    "\n",
    "bottom_left = CoordPair(lat=29.5, lon=-110)\n",
    "top_right = CoordPair(lat=30.0, lon=-109.3)\n",
    "\n",
    "geo_bounds = GeoBounds(bottom_left, top_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Setting the Cartopy Extents\n",
    "\n",
    "After setting up the GeoBounds objects, you can use *cartopy_xlim* and *cartopy_ylim* functions to set the extents.  \n",
    "\n",
    "Note: Cartopy also has an API for doing this, but it doesn't work correctly for some projections like RotatedPole.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from wrf import (CoordPair, GeoBounds, getvar, \n",
    "                 cartopy_xlim, cartopy_ylim)\n",
    "\n",
    "file_path = \"/Users/ladwig/wrf_tutorial_data/wrfout_d01_2010-06-02_00_00_00\"\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "slp = getvar(wrf_file, \"slp\", timeidx=0)\n",
    "\n",
    "bottom_left = CoordPair(lat=29.5, lon=-110)\n",
    "top_right = CoordPair(lat=30.0, lon=-109.3)\n",
    "\n",
    "geo_bounds = GeoBounds(bottom_left, top_right)\n",
    "\n",
    "fig = pyplot.figure(figsize=(10, 7.5))\n",
    "geo_axes = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "#. \n",
    "#. Draw contours, add geographic features, etc.\n",
    "#. \n",
    "\n",
    "xlim = cartopy_xlim(slp, geobounds=geo_bounds)               \n",
    "geo_axes.set_xlim(xlim)\n",
    "         \n",
    "ylim = cartopy_ylim(slp, geobounds=geo_bounds)               \n",
    "geo_axes.set_ylim(ylim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 5.6: Cropping by Setting the X,Y Extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, to_np, get_cartopy, latlon_coords\n",
    "from wrf import xy_to_ll, cartopy_xlim, cartopy_ylim\n",
    "from wrf import CoordPair, GeoBounds\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Get precipitable water in kg/m2 [or mm]\n",
    "pw = getvar(wrf_file, \"pw\")\n",
    "\n",
    "# Get the Precipitable Water in inches \n",
    "# [Note: 1 kg/m2 = 1 mm = .0393701 in]\n",
    "pw_in = pw * .0393701\n",
    "\n",
    "# After a math operation, xarray drops the attributes, so \n",
    "# let's add them back and set the units to be inches\n",
    "pw_in.attrs.update(pw.attrs)\n",
    "pw_in.attrs[\"units\"] = \"in\"\n",
    "\n",
    "# Get the cartopy object and the lat,lon coords\n",
    "cart_proj = get_cartopy(pw_in)\n",
    "lats, lons = latlon_coords(pw_in)\n",
    "\n",
    "# Create a figure and get the GetAxes object\n",
    "fig = pyplot.figure(figsize=(9, 10))\n",
    "geo_axes = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and add the states\n",
    "# See the cartopy documentation for more on this\n",
    "states = NaturalEarthFeature(category='cultural', \n",
    "                             scale='50m', \n",
    "                             facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "geo_axes.add_feature(states, linewidth=2.0, edgecolor='black', zorder=2)\n",
    "\n",
    "# Set the contour levels\n",
    "levels = np.arange(0, 1.4, .2)\n",
    "\n",
    "# Make the contour lines and fill them.\n",
    "pyplot.contour(to_np(lons), to_np(lats), \n",
    "               to_np(pw_in), levels=levels, colors=\"black\",\n",
    "               transform=crs.PlateCarree())\n",
    "pyplot.contourf(to_np(lons), to_np(lats), \n",
    "                to_np(pw_in), levels=levels, \n",
    "                transform=crs.PlateCarree(),\n",
    "                cmap=get_cmap(\"jet\"))\n",
    "             \n",
    "# Add a color bar. The shrink often needs to be set \n",
    "# by trial and error.\n",
    "pyplot.colorbar(ax=geo_axes, shrink=1.0)\n",
    "\n",
    "# Set up the x, y extents\n",
    "\n",
    "# Determine the center of the domain in grid coordinates\n",
    "pw_shape = pw_in.shape\n",
    "start_y = 0\n",
    "center_y = int(pw_shape[-2]/2.) - 1\n",
    "center_x = int(pw_shape[-1]/2.) - 1\n",
    "end_x = int(pw_shape[-1]) - 1\n",
    "\n",
    "# Get the lats and lons for the start, center, and end points\n",
    "# (Normally you would just set these yourself)\n",
    "center_latlon = xy_to_ll(wrf_file, \n",
    "                         [center_x, end_x], \n",
    "                         [start_y, center_y])\n",
    "\n",
    "start_lat = center_latlon[0,0]\n",
    "end_lat = center_latlon[0,1]\n",
    "start_lon = center_latlon[1,0]\n",
    "end_lon = center_latlon[1,1]\n",
    "\n",
    "# Set the extents\n",
    "geo_bounds = GeoBounds(CoordPair(lat=start_lat, lon=start_lon),\n",
    "                       CoordPair(lat=end_lat, lon=end_lon))\n",
    "geo_axes.set_xlim(cartopy_xlim(pw_in, geobounds=geo_bounds))\n",
    "geo_axes.set_ylim(cartopy_ylim(pw_in, geobounds=geo_bounds))\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6.0 OpenMP and Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Beginning in version 1.1.0, the wrf-python computational routines support OpenMP directives.\n",
    "- All routines are set to use a *runtime* scheduler, so users can specify the scheduler themselves.\n",
    "- The full runtime library is available for OpenMP 3.1, but most functions aren't useful.\n",
    "- By default, wrf-python is set to use 1 thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Useful OpenMP Library Functions\n",
    "\n",
    "- **omp_enabled**: Returns True if wrf-python has been compiled with OpenMP features.\n",
    "- **omp_get_num_procs**: Return the number of CPUs on this machine.\n",
    "- **omp_set_num_threads**: Set the number of threads (i.e. CPUs) to use.\n",
    "- **omp_set_schedule**: Specify the type of scheduling to use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Setting WRF-Python to Use Max Number of Threads/CPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrf import omp_enabled, omp_get_num_procs, omp_set_num_threads\n",
    "\n",
    "if not omp_enabled():\n",
    "    raise RuntimeError(\"OpenMP is not available in this build\")\n",
    "\n",
    "omp_set_num_threads(omp_get_num_procs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 6.1: Performance Improvement with OpenMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, ALL_TIMES, omp_enabled, \n",
    "                 omp_get_num_procs, omp_set_num_threads)\n",
    "\n",
    "if not omp_enabled():\n",
    "    raise RuntimeError(\"OpenMP is not available in this build\")\n",
    "\n",
    "# For this demo, only use the first file since there are 24 time steps\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "wrf_file = Dataset(file_path)\n",
    "    \n",
    "vars = (\"avo\", \"eth\", \"cape_2d\", \"cape_3d\", \"ctt\", \"dbz\", \"mdbz\",\n",
    "        \"geopt\", \"helicity\", \"lat\", \"lon\", \"omg\", \"p\", \"pressure\",\n",
    "        \"pvo\", \"pw\", \"rh2\", \"rh\", \"slp\", \"ter\", \"td2\", \"td\", \"tc\",\n",
    "        \"theta\", \"tk\", \"tv\", \"twb\", \"updraft_helicity\", \"ua\", \"va\",\n",
    "        \"wa\", \"uvmet10\", \"uvmet\", \"z\", \"cfrac\")    \n",
    "\n",
    "print(\"Running with a single CPU\")\n",
    "\n",
    "# Use 1 CPU\n",
    "omp_set_num_threads(1)\n",
    "\n",
    "start = time()\n",
    "\n",
    "for var in vars:\n",
    "    v = getvar(wrf_file, var, 0)\n",
    "    \n",
    "end = time()\n",
    "\n",
    "print(\"Time taken: {} s\".format(end-start))\n",
    "\n",
    "print (\"Running with {} CPUs\".format(omp_get_num_procs()))\n",
    "\n",
    "# Use Max CPUs\n",
    "omp_set_num_threads(omp_get_num_procs())\n",
    "\n",
    "start = time()\n",
    "\n",
    "for var in vars:\n",
    "    v = getvar(wrf_file, var, 0)\n",
    "    \n",
    "end = time()\n",
    "\n",
    "print(\"Time taken: {} s\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Well that was disappointing...\n",
    "\n",
    "Let's test the OpenMP schedulers to see if that improves the situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## OpenMP Scheduling Types\n",
    "\n",
    "WRF-Python uses *runtime* scheduling, which means that one of the scheduler types defined below must be set at runtime rather than compile time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## OpenMP Scheduling Types\n",
    "\n",
    "- **OMP_SCHED_STATIC**: Divide the loop in to equal-sized chunks (default chunk_size = loop_count/num_threads)\n",
    "  **[wrf-python default]**\n",
    "  \n",
    "- **OMP_SCHED_DYNAMIC**: Use internal loop queue to give a chunk-sized block of loop iterations to each thread. \n",
    "  When thread is finished, it retrieves next block to work on (default chunk_size = 1).\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## OpenMP Scheduling Types\n",
    "\n",
    "- **OMP_SCHED_GUIDED**: Similar to OMP_SCHED_DYNAMIC, but the chunk size starts off large and decreases to better \n",
    "  handle load imbalance between iterations. (default chunk_size = loop_count/num_threads)\n",
    "  \n",
    "- **OMP_SCHED_AUTO**: The decision regarding scheduling is delegated to the OpenMP implementation for the compiler \n",
    "  (magic!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Setting the OpenMP Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrf import (omp_set_schedule, OMP_SCHED_STATIC, OMP_SCHED_DYNAMIC, \n",
    "                 OMP_SCHED_GUIDED, OMP_SCHED_AUTO)\n",
    "\n",
    "# A value of 0 means to use the OpenMP default\n",
    "chunk_size = 0 \n",
    "\n",
    "omp_set_schedule(OMP_SCHED_GUIDED, chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 6.2: OpenMP Scheduling Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, ALL_TIMES, omp_enabled, \n",
    "                 omp_get_num_procs, omp_set_num_threads,\n",
    "                 omp_set_schedule, OMP_SCHED_STATIC,\n",
    "                 OMP_SCHED_DYNAMIC, \n",
    "                 OMP_SCHED_GUIDED, OMP_SCHED_AUTO)\n",
    "\n",
    "if not omp_enabled():\n",
    "    raise RuntimeError(\"OpenMP is not available in this build\")\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "wrf_file = Dataset(file_path)\n",
    "    \n",
    "vars = (\"avo\", \"eth\", \"cape_2d\", \"cape_3d\", \"ctt\", \"dbz\", \"mdbz\",\n",
    "        \"geopt\", \"helicity\", \"lat\", \"lon\", \"omg\", \"p\", \"pressure\",\n",
    "        \"pvo\", \"pw\", \"rh2\", \"rh\", \"slp\", \"ter\", \"td2\", \"td\", \"tc\",\n",
    "        \"theta\", \"tk\", \"tv\", \"twb\", \"updraft_helicity\", \"ua\", \"va\",\n",
    "        \"wa\", \"uvmet10\", \"uvmet\", \"z\", \"cfrac\")    \n",
    "\n",
    "omp_set_num_threads(omp_get_num_procs())\n",
    "\n",
    "chunk_size = 0\n",
    "\n",
    "sched_string_map = {int(OMP_SCHED_STATIC) : \"OMP_SCHED_STATIC\", \n",
    "                    int(OMP_SCHED_DYNAMIC) : \"OMP_SCHED_DYNAMIC\",  \n",
    "                    int(OMP_SCHED_GUIDED) : \"OMP_SCHED_GUIDED\",\n",
    "                    int(OMP_SCHED_AUTO) : \"OMP_SCHED_AUTO\"}\n",
    "\n",
    "for sched in (OMP_SCHED_STATIC, OMP_SCHED_DYNAMIC, \n",
    "              OMP_SCHED_GUIDED, OMP_SCHED_AUTO):\n",
    "    omp_set_schedule(sched, chunk_size)\n",
    "    sched_string = sched_string_map[int(sched)]\n",
    "    print(\"Running with sheduler: {}\".format(sched_string))\n",
    "    \n",
    "    start = time()\n",
    "    for var in vars:\n",
    "        v = getvar(wrf_file, var, 0)\n",
    "    end = time()\n",
    "    \n",
    "    print(\"Time taken using scheduler {}: {} s\".format(sched_string, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Well that didn't help much...\n",
    "\n",
    "What else could be causing this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**When in doubt, blame I/O.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## WRF-Python and Variable Extraction\n",
    "\n",
    "- Every time you call *wrf.getvar*, the variables needed for the calculation are extracted from the NetCDF file.\n",
    "- The same variables are going to be extracted over and over and over and over and...\n",
    "- To prevent this, you can use the *cache* argument to getvar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The cache Argument to getvar\n",
    "\n",
    "- Normally used internally so that variables containing metadata aren't extracted more than once.\n",
    "- Can also be used to prevent the repeated extraction of common variables.\n",
    "- Should be a dictionary of variable name to variable data (*wrf.extract_vars* will return this).\n",
    "- Good variables to use: **P, PB, PH, PHB, T, QVAPOR, HGT, PSFC, U, V, W**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Using extract_vars to Make a Variable Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import extract_vars, ALL_TIMES\n",
    "\n",
    "file_paths = multiple_wrf_files()\n",
    "\n",
    "wrf_files = [Dataset(f) for f in file_paths]\n",
    "\n",
    "# Note: Make sure that your timeidx argument matches what\n",
    "# you will use for your call to getvar\n",
    "cache = extract_vars(wrf_files, ALL_TIMES, \n",
    "                     (\"P\", \"PSFC\", \"PB\", \"PH\", \"PHB\",\n",
    "                      \"T\", \"QVAPOR\", \"HGT\", \"U\", \"V\",\n",
    "                      \"W\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "### Example 6.3: Using the cache Argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, extract_vars, ALL_TIMES, omp_enabled, \n",
    "                 omp_get_num_procs, omp_set_num_threads,\n",
    "                 omp_set_schedule, OMP_SCHED_STATIC,\n",
    "                 OMP_SCHED_DYNAMIC, \n",
    "                 OMP_SCHED_GUIDED, OMP_SCHED_AUTO)\n",
    "\n",
    "if not omp_enabled():\n",
    "    raise RuntimeError(\"OpenMP is not available in this build\")\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "print(\"Caching common variables\")\n",
    "cache = extract_vars(wrf_file, 0, \n",
    "                     (\"P\", \"PSFC\", \"PB\", \"PH\", \"PHB\",\n",
    "                      \"T\", \"QVAPOR\", \"HGT\", \"U\", \"V\",\n",
    "                      \"W\"))\n",
    "print(\"Finished caching\")\n",
    "print(\"----------------\")\n",
    "    \n",
    "vars = (\"avo\", \"eth\", \"cape_2d\", \"cape_3d\", \"ctt\", \"dbz\", \"mdbz\",\n",
    "        \"geopt\", \"helicity\", \"lat\", \"lon\", \"omg\", \"p\", \"pressure\",\n",
    "        \"pvo\", \"pw\", \"rh2\", \"rh\", \"slp\", \"ter\", \"td2\", \"td\", \"tc\",\n",
    "        \"theta\", \"tk\", \"tv\", \"twb\", \"updraft_helicity\", \"ua\", \"va\",\n",
    "        \"wa\", \"uvmet10\", \"uvmet\", \"z\", \"cfrac\")    \n",
    "\n",
    "omp_set_num_threads(omp_get_num_procs())\n",
    "\n",
    "chunk_size = 0\n",
    "\n",
    "sched_string_map = {int(OMP_SCHED_STATIC) : \"OMP_SCHED_STATIC\", \n",
    "                    int(OMP_SCHED_DYNAMIC) : \"OMP_SCHED_DYNAMIC\",  \n",
    "                    int(OMP_SCHED_GUIDED) : \"OMP_SCHED_GUIDED\",\n",
    "                    int(OMP_SCHED_AUTO) : \"OMP_SCHED_AUTO\"}\n",
    "\n",
    "for sched in (OMP_SCHED_STATIC, OMP_SCHED_DYNAMIC, \n",
    "              OMP_SCHED_GUIDED, OMP_SCHED_AUTO):\n",
    "    omp_set_schedule(sched, chunk_size)\n",
    "    sched_string = sched_string_map[int(sched)]\n",
    "    print(\"Running with sheduler: {}\".format(sched_string))\n",
    "    \n",
    "    start = time()\n",
    "    for var in vars:\n",
    "        v = getvar(wrf_file, var, 0, cache=cache)\n",
    "    end = time()\n",
    "    \n",
    "    print(\"Time taken using scheduler {}: {} s\".format(sched_string, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That's more like it!\n",
    "\n",
    "About a 60% reduction in computation time from the original single threaded case! \n",
    "\n",
    "(For Python 2.7, where I/O is faster, it's closer to 70%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 7.0 Advanced Examples\n",
    "\n",
    "Here comes the real world!\n",
    "\n",
    "These examples are a significant jump in difficulty from the previous ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 7.1: Overlaying Multiple Diagnostics\n",
    "\n",
    "In this example, we're going to add winds and dewpoint to sea level pressure\n",
    "\n",
    "[Note: not the most useful plot for the mountains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, to_np, get_cartopy, latlon_coords, \n",
    "                 cartopy_xlim, cartopy_ylim)\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Get the slp, td2, u, and v variables\n",
    "slp = getvar(wrf_file, \"slp\", timeidx=0)\n",
    "td2 = getvar(wrf_file, \"td2\", timeidx=0, units=\"degF\")\n",
    "u_sfc = getvar(wrf_file, \"ua\", timeidx=0, units=\"kt\")[0,:]\n",
    "v_sfc = getvar(wrf_file, \"va\", timeidx=0, units=\"kt\")[0,:]\n",
    "\n",
    "# Get the cartopy object and the lat,lon coords\n",
    "cart_proj = get_cartopy(slp)\n",
    "lats, lons = latlon_coords(slp)\n",
    "\n",
    "# Create a figure and get the GetAxes object\n",
    "fig = pyplot.figure(figsize=(9, 10))\n",
    "geo_axes = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and add the states and coastlines\n",
    "# See the cartopy documentation for more on this.\n",
    "states = NaturalEarthFeature(category='cultural', \n",
    "                             scale='50m', \n",
    "                             facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "geo_axes.add_feature(states, linewidth=2.0, edgecolor='black', zorder=2)\n",
    "\n",
    "\n",
    "# Manually setting the contour levels\n",
    "slp_levels = np.arange(980.,1030.,6.0)\n",
    "td2_levels = np.arange(10., 79., 3.)\n",
    "\n",
    "\n",
    "# Manually setting the td2 RGB colors (normalized to 1)\n",
    "# These colors originated from the now defunct hoot.metr.ou.edu\n",
    "# They work well for detecting moisture boundaries (e.g. the dryline)\n",
    "td2_rgb = np.array([[181,82,0], [181,82,0],\n",
    "                  [198,107,8], [206,107,8],\n",
    "                  [231,140,8], [239,156,8],\n",
    "                  [247,173,24], [255,189,41],\n",
    "                  [255,212,49], [255,222,66],\n",
    "                  [255,239,90], [247,255,123],\n",
    "                  [214,255,132], [181,231,148],\n",
    "                  [156,222,156], [132,222,132],\n",
    "                  [112,222,112], [82,222,82],\n",
    "                  [57,222,57], [33,222,33],\n",
    "                  [8,206,8], [0,165,0],\n",
    "                  [0,140,0], [3,105,3]]) / 255.0\n",
    "    \n",
    "td2_cmap, td2_norm = from_levels_and_colors(td2_levels, td2_rgb, \n",
    "                                            extend=\"both\")\n",
    "\n",
    "# Make the pressure contour lines\n",
    "slp_contours = pyplot.contour(to_np(lons), \n",
    "                              to_np(lats), \n",
    "                              to_np(slp), \n",
    "                              levels=slp_levels, \n",
    "                              colors=\"black\",\n",
    "                              transform=crs.PlateCarree())\n",
    "\n",
    "# Make filled contours of dewpoint\n",
    "pyplot.contourf(to_np(lons), \n",
    "                to_np(lats), \n",
    "                to_np(td2), \n",
    "                levels=td2_levels, \n",
    "                cmap=td2_cmap, \n",
    "                norm=td2_norm,\n",
    "                extend=\"both\",\n",
    "                transform=crs.PlateCarree())\n",
    "\n",
    "# Plot the wind barbs, but only plot ~10 barbs in each direction.\n",
    "thin = [int(x/10.) for x in lons.shape]\n",
    "pyplot.barbs(to_np(lons[::thin[0], ::thin[1]]), \n",
    "             to_np(lats[::thin[0], ::thin[1]]), \n",
    "             to_np(u_sfc[::thin[0], ::thin[1]]), \n",
    "             to_np(v_sfc[::thin[0], ::thin[1]]),\n",
    "             transform=crs.PlateCarree())\n",
    "\n",
    "# Add contour labels for pressure\n",
    "pyplot.clabel(slp_contours, fmt=\"%i\")\n",
    "\n",
    "# Add a color bar. The shrink often needs to be set \n",
    "# by trial and error.\n",
    "pyplot.colorbar(ax=geo_axes, shrink=1.0, extend=\"both\")\n",
    "\n",
    "# Set the map bounds\n",
    "pyplot.xlim(cartopy_xlim(slp))\n",
    "pyplot.ylim(cartopy_ylim(slp))\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 7.2: 500 hPa RH and Winds with interplevel\n",
    "\n",
    "In this example, the 500 hPa relative humidity is plotted with wind barbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, to_np, get_cartopy, latlon_coords, interplevel,\n",
    "                 cartopy_xlim, cartopy_ylim)\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Extract the pressure, relative humidity, and wind variables\n",
    "p = getvar(wrf_file, \"pressure\")\n",
    "rh = getvar(wrf_file, \"rh\")\n",
    "ua = getvar(wrf_file, \"ua\", units=\"kt\")\n",
    "va = getvar(wrf_file, \"va\", units=\"kt\")\n",
    "\n",
    "# Interpolate rh, u, and v winds at the level specified below\n",
    "level = 500.\n",
    "rh_level = interplevel(rh, p, level)\n",
    "u_level = interplevel(ua, p, level)\n",
    "v_level = interplevel(va, p, level)\n",
    "\n",
    "# Get the lat/lon coordinates\n",
    "lats, lons = latlon_coords(rh_level)\n",
    "\n",
    "# Get the map projection information\n",
    "cart_proj = get_cartopy(rh_level)\n",
    "\n",
    "# Create the figure\n",
    "fig = pyplot.figure(figsize=(9,10))\n",
    "ax = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and add the states and coastlines\n",
    "states = NaturalEarthFeature(category='cultural', \n",
    "                             scale='50m', \n",
    "                             facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "ax.add_feature(states, linewidth=2.0, edgecolor='black', zorder=2)\n",
    "\n",
    "# Add the RH contour lines\n",
    "levels = np.arange(0, 110, 10)\n",
    "contours = pyplot.contourf(to_np(lons), \n",
    "                           to_np(lats), \n",
    "                           to_np(rh_level), \n",
    "                           levels=levels, \n",
    "                           cmap=get_cmap(\"PRGn\"),\n",
    "                           transform=crs.PlateCarree())\n",
    "\n",
    "pyplot.colorbar(contours, ax=ax, shrink=1.0)\n",
    "\n",
    "# Add the wind barbs, only plotting 10 barbs in each direction\n",
    "# Also, skip the border barbs\n",
    "thin = [int(x/10.) for x in lons.shape]\n",
    "pyplot.barbs(to_np(lons[::thin[0], ::thin[1]]), \n",
    "             to_np(lats[::thin[0], ::thin[1]]), \n",
    "             to_np(u_level[::thin[0], ::thin[1]]),\n",
    "             to_np(v_level[::thin[0], ::thin[1]]), \n",
    "             length=6,\n",
    "             transform=crs.PlateCarree())\n",
    "\n",
    "# Set the map bounds\n",
    "ax.set_xlim(cartopy_xlim(rh_level))\n",
    "ax.set_ylim(cartopy_ylim(rh_level))\n",
    "\n",
    "ax.gridlines()\n",
    "\n",
    "pyplot.title(\"{} MB RH (%) and Barbs (kt)\".format(int(level)))\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 7.3: Precipitation Accumulation\n",
    "\n",
    "- To get total precipitation accumulation for WRF, you need to add the cumulus precipitation (RAINC) and grid scale (microphysics) precipitation (RAINNC) values together.\n",
    "\n",
    "        total_accum_precip = RAINC + RAINNC\n",
    "    \n",
    "- The accumulation values are from the start of the WRF simulation.\n",
    "- To get the precipitation for some time period, you need to subtract the value for the start of the accumulation period from the end of the accumulation period.\n",
    "\n",
    "   For example, for one time period (usually 1 hour):\n",
    "\n",
    "      accum_for_1hr = total_accum_precip[n] - \n",
    "                      total_accum_precip[n-1]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Precipitation Buckets\n",
    "\n",
    "- For long running simulations, buckets are used to prevent inaccuracies with adding large and small 32-bit floating point numbers. \n",
    "- When a precipitation threshold is met, an integer variable is incremented and the accumulation variable reset to 0.\n",
    "- Accumulation variables are I_RAINC and I_RAINNC.\n",
    "- The bucket size is set in the BUCKET_MM global attribute (-1 when buckets are disabled).\n",
    "\n",
    "To get the total accumulated precipitation with buckets:\n",
    "    \n",
    "    total_accum_precip = (I_RAINC * bucket_mm + RAINC) +\n",
    "                         (I_RAINNC * bucket_mm + RAINNC)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this example, the precipitation accumulation for one day is plotted every 4 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import from_levels_and_colors, LinearSegmentedColormap\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature, COLORS\n",
    "from netCDF4 import Dataset\n",
    "from xarray import DataArray\n",
    "from wrf import (getvar, extract_global_attrs, ALL_TIMES, to_np, get_cartopy, \n",
    "                 latlon_coords, vertcross, cartopy_xlim, cartopy_ylim, interpline)\n",
    "\n",
    "\n",
    "file_paths = multiple_wrf_files()\n",
    "wrf_files = [Dataset(file_path) for file_path in file_paths]\n",
    "\n",
    "# Get the WRF precipitation variables\n",
    "rainc = getvar(wrf_files, \"RAINC\", ALL_TIMES)\n",
    "rainnc = getvar(wrf_files, \"RAINNC\", ALL_TIMES)\n",
    "i_rainc = getvar(wrf_files, \"I_RAINC\", ALL_TIMES)\n",
    "i_rainnc = getvar(wrf_files, \"I_RAINNC\", ALL_TIMES)\n",
    "bucket_mm = extract_global_attrs(wrf_files, (\"BUCKET_MM\",))[\"BUCKET_MM\"]\n",
    "\n",
    "# This is \"RAINC + RAINNC\" using precip buckets\n",
    "total_accum = (i_rainc * bucket_mm + rainc) + (i_rainnc * bucket_mm + rainnc)\n",
    "\n",
    "# Get the precipitation accumulations in 4 hour periods\n",
    "# This numpy notation is the same as:\n",
    "#     four_hour_accums[0,:] = total_accum[4, :] - total_accum[0,:]\n",
    "#     four_hour_accums[1,:] = total_accum[8, :] - total_accum[0,:]\n",
    "#     four_hour_accums[2,:] = total_accum[12, :] - total_accum[0,:]\n",
    "#     ...\n",
    "four_hour_accums = total_accum[4:25:4,:] - total_accum[0,:]\n",
    "\n",
    "# Convert the precipitation from mm to inches\n",
    "four_hour_accums = four_hour_accums * 0.0393701\n",
    "\n",
    "# Let's set the metadata for this variable\n",
    "four_hour_accums.name = \"PRECIP_4HR\"\n",
    "four_hour_accums.attrs.update(rainc.attrs)\n",
    "four_hour_accums.attrs[\"description\"] = \"precip accumulation 4 hour intervals\"\n",
    "four_hour_accums.attrs[\"units\"] = \"in\"\n",
    "# Let's make a new secondary coordinate for the time interval labels\n",
    "four_hour_accums.coords[\"accum_hrs\"] = (\"Time\", [4, 8, 12, 16, 20, 24])\n",
    "\n",
    "# Get the lat/lon points\n",
    "lats, lons = latlon_coords(four_hour_accums)\n",
    "\n",
    "# Get the cartopy projection object\n",
    "cart_proj = get_cartopy(four_hour_accums)\n",
    "\n",
    "# Create the figure\n",
    "fig = pyplot.figure(figsize=(12,20))\n",
    "\n",
    "# Download and create the states, land, and oceans using cartopy features\n",
    "states = NaturalEarthFeature(category='cultural', scale='50m', facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "land = NaturalEarthFeature(category='physical', name='land', scale='50m',\n",
    "                           facecolor=COLORS['land'])\n",
    "\n",
    "# Making precipitation levels using several groupings of evenly spaced levels\n",
    "# (taken from www.twisterdata.com).\n",
    "precip_levels = np.append(np.arange(.01, .05, .02), np.arange(.05, .30, .05))\n",
    "precip_levels = np.append(precip_levels, np.arange(.30, 1.0, .1))\n",
    "precip_levels = np.append(precip_levels, np.arange(1.0, 2.0, .25))\n",
    "precip_levels = np.append(precip_levels, np.arange(2.0, 5.0, .5))\n",
    "\n",
    "# Here is how you can truncate an existing colormap in to a subset of it.\n",
    "orig_cmap = get_cmap(\"gist_ncar\")\n",
    "cmap = LinearSegmentedColormap.from_list(\"gist_ncar_trunc\", \n",
    "                                         orig_cmap(np.linspace(.12, .9, 256)))\n",
    "\n",
    "# Make the 6 subplots\n",
    "for plotid in range(6):\n",
    "    \n",
    "    # The figure that will have 6 subplots (3 rows, 2 columns)\n",
    "    # Note: subplot indexes start at 1 instead of 0\n",
    "    ax = fig.add_subplot(3,2,plotid+1, projection=cart_proj)\n",
    "\n",
    "    accum = four_hour_accums[plotid,:]\n",
    "    accum_hr = int(accum[\"accum_hrs\"])\n",
    "    \n",
    "    # Make the precip accum contours\n",
    "    precip_contours = ax.contourf(to_np(lons), \n",
    "                                  to_np(lats), \n",
    "                                  to_np(accum), \n",
    "                                  levels=precip_levels,  \n",
    "                                  cmap=cmap,\n",
    "                                  zorder=2,\n",
    "                                  transform=crs.PlateCarree())\n",
    "\n",
    "\n",
    "    # Draw the oceans, land, and states\n",
    "    ax.add_feature(states, linewidth=2.0, edgecolor=\"white\", zorder=3)\n",
    "    ax.add_feature(land, zorder=1)\n",
    "    \n",
    "    cb_precip = fig.colorbar(precip_contours, ax=ax)\n",
    "    \n",
    "    ax.set_xlim(cartopy_xlim(accum))\n",
    "    ax.set_ylim(cartopy_ylim(accum))\n",
    "\n",
    "    # Add a title\n",
    "    ax.set_title(\"Precip Accum (in) After {} Hours\".format(accum_hr), \n",
    "                 {\"fontsize\" : 12})\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 7.4: Cross Section Panel Plot\n",
    "\n",
    "In this example, a panel plot is created with one plot showing maximum reflectivity with the horizontal cross section line, and the second plot is a vertical cross section for radar reflectivity with the terrain heights added to show the mountains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Begin by defining a cross section line in latitude, longitude coordinates.\n",
    "\n",
    "You must run this first, or the next group of cells will throw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrf import CoordPair\n",
    "\n",
    "cross_start = CoordPair(lat=43.5, lon=-116.5)\n",
    "cross_end = CoordPair(lat=43.5, lon=-114)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Note: the original values were:\n",
    "``` python\n",
    "cross_start = CoordPair(lat=43.5, lon=-116.5)\n",
    "cross_end = CoordPair(lat=43.5, lon=-114.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature, COLORS\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, to_np, get_cartopy, latlon_coords, vertcross,\n",
    "                 cartopy_xlim, cartopy_ylim, interpline)\n",
    "\n",
    "try:\n",
    "    cross_start\n",
    "    cross_end\n",
    "except NameError:\n",
    "    raise RuntimeError(\"you didn't run the previous cell\")\n",
    "\n",
    "file_path = multiple_wrf_files()\n",
    "wrf_file = [Dataset(x) for x in file_path]\n",
    "\n",
    "# Get the WRF variables\n",
    "ht = getvar(wrf_file, \"z\", timeidx=-1)\n",
    "ter = getvar(wrf_file, \"ter\", timeidx=-1)\n",
    "dbz = getvar(wrf_file, \"dbz\", timeidx=-1)\n",
    "max_dbz = getvar(wrf_file, \"mdbz\", timeidx=-1)\n",
    "Z = 10**(dbz/10.) # Use linear Z for interpolation\n",
    "\n",
    "# Compute the vertical cross-section interpolation.  Also, include the lat/lon\n",
    "# points along the cross-section in the metadata by setting latlon to True.\n",
    "z_cross = vertcross(Z, ht, wrfin=wrf_file, \n",
    "                    start_point=cross_start, \n",
    "                    end_point=cross_end,\n",
    "                    latlon=True, meta=True)\n",
    "\n",
    "# Convert back to dBz after interpolation\n",
    "dbz_cross = 10.0 * np.log10(z_cross)\n",
    "\n",
    "# Add back the attributes that xarray dropped from the operations above\n",
    "dbz_cross.attrs.update(z_cross.attrs)\n",
    "dbz_cross.attrs[\"description\"] = \"radar reflectivity cross section\"\n",
    "dbz_cross.attrs[\"units\"] = \"dBZ\"\n",
    "\n",
    "# To remove the slight gap between the dbz and terrain due to contouring, \n",
    "# the new vertical grid spacing, and grid staggering, let's fill in the \n",
    "# lower grid cells with the first non-missing value for each column.\n",
    "\n",
    "# Make a copy of the z cross data. Let's use regular numpy arrays for this.\n",
    "dbz_cross_filled = np.ma.copy(to_np(dbz_cross))\n",
    "\n",
    "# For each cross section column, find the first index with non-missing values \n",
    "# and copy these to the missing elements below.\n",
    "for i in range(dbz_cross_filled.shape[-1]):\n",
    "    column_vals = dbz_cross_filled[:,i]\n",
    "    # Let's find all values that aren't filled. The nonzero function checks \n",
    "    # for nonzero values, but 0s are ok for reflectivity, so let's just \n",
    "    # get all values greater than some nonsensical negative and use nonzero() \n",
    "    # on the boolean array. \n",
    "    first_idx = int(np.transpose((column_vals > -200.).nonzero())[0])\n",
    "    dbz_cross_filled[0:first_idx, i] = dbz_cross_filled[first_idx, i]\n",
    "            \n",
    "# Get the terrain heights along the cross section line\n",
    "ter_line = interpline(ter, wrfin=wrf_file, start_point=cross_start, \n",
    "                      end_point=cross_end)\n",
    "\n",
    "# Get the lat/lon points\n",
    "lats, lons = latlon_coords(dbz)\n",
    "\n",
    "# Get the cartopy projection object\n",
    "cart_proj = get_cartopy(dbz)\n",
    "\n",
    "# Create a figure that will have 2 subplots (1 row, 2 columns)\n",
    "fig = pyplot.figure(figsize=(18,6))\n",
    "ax_dbz = fig.add_subplot(1,2,1,projection=cart_proj)\n",
    "ax_cross = fig.add_subplot(1,2,2)\n",
    "\n",
    "# Download and create the states and land\n",
    "states = NaturalEarthFeature(category='cultural', scale='50m', facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "land = NaturalEarthFeature(category='physical', name='land', scale='50m',\n",
    "                           facecolor=COLORS['land'])\n",
    "\n",
    "dbz_levels = np.arange(5., 80., 5.)\n",
    "\n",
    "# This is the NWS color table.\n",
    "dbz_rgb = np.array([[4,233,231],\n",
    "                    [1,159,244], [3,0,244],\n",
    "                    [2,253,2], [1,197,1],\n",
    "                    [0,142,0], [253,248,2],\n",
    "                    [229,188,0], [253,149,0],\n",
    "                    [253,0,0], [212,0,0],\n",
    "                    [188,0,0],[248,0,253],\n",
    "                    [152,84,198],[253,253,253]], np.float32) / 255.0\n",
    "    \n",
    "dbz_map, dbz_norm = from_levels_and_colors(dbz_levels, dbz_rgb, extend=\"max\")\n",
    "\n",
    "# Make the dbz contours on the map\n",
    "dbz_contours = ax_dbz.contourf(to_np(lons), \n",
    "                    to_np(lats), \n",
    "                    to_np(max_dbz), \n",
    "                    levels=dbz_levels,\n",
    "                    cmap=dbz_map, \n",
    "                    norm=dbz_norm, \n",
    "                    extend=\"max\",\n",
    "                    zorder=3, \n",
    "                    transform=crs.PlateCarree())\n",
    "\n",
    "# Draw the cross section line\n",
    "ax_dbz.plot([cross_start.lon, cross_end.lon], \n",
    "            [cross_start.lat, cross_end.lat],\n",
    "            color=\"black\",\n",
    "            linewidth=3.0,\n",
    "            marker=\"o\",  \n",
    "            zorder=5,\n",
    "            transform=crs.PlateCarree())\n",
    "\n",
    "# Draw the oceans, land, and states\n",
    "ax_dbz.add_feature(states, linewidth=2.0, edgecolor=\"black\", zorder=3)\n",
    "ax_dbz.add_feature(land)\n",
    "\n",
    "# Make the cross section plot for dbz\n",
    "dbz_levels = np.arange(5.,75.,5.)\n",
    "xs = np.arange(0, dbz_cross.shape[-1], 1)\n",
    "ys = to_np(dbz_cross.coords[\"vertical\"])\n",
    "dbz_contours = ax_cross.contourf(xs, \n",
    "                                 ys, \n",
    "                                 to_np(dbz_cross_filled), \n",
    "                                 levels=dbz_levels,\n",
    "                                 cmap=dbz_map, \n",
    "                                 norm=dbz_norm, \n",
    "                                 extend=\"max\")\n",
    "cb_dbz = fig.colorbar(dbz_contours, ax=ax_cross)\n",
    "cb_dbz.ax.tick_params(labelsize=8)\n",
    "\n",
    "# Fill in the mountain area\n",
    "ht_fill = ax_cross.fill_between(xs, 0, to_np(ter_line), \n",
    "                                facecolor=\"saddlebrown\")\n",
    "\n",
    "# Set the x-ticks to use latitude and longitude labels\n",
    "coord_pairs = to_np(dbz_cross.coords[\"xy_loc\"])\n",
    "x_ticks = np.arange(coord_pairs.shape[0])\n",
    "x_labels = [pair.latlon_str() for pair in to_np(coord_pairs)]\n",
    "\n",
    "# Set the desired number of x ticks below\n",
    "num_ticks = 5\n",
    "thin = int((len(x_ticks) / num_ticks) + .5)\n",
    "ax_cross.set_xticks(x_ticks[::thin])\n",
    "ax_cross.set_xticklabels(x_labels[::thin], rotation=45, fontsize=8)\n",
    "\n",
    "# Set the x-axis and  y-axis labels\n",
    "ax_cross.set_xlabel(\"Latitude, Longitude\", fontsize=12)\n",
    "ax_cross.set_ylabel(\"Height (m)\", fontsize=12)\n",
    "\n",
    "# Add a title\n",
    "ax_dbz.set_title(\"Maximum Reflectivity (dBZ)\", {\"fontsize\" : 14})\n",
    "ax_cross.set_title(\"Cross-Section of Reflectivity (dBZ)\", {\"fontsize\" : 14})\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 7.5: Animations\n",
    "\n",
    "In this example, an animation of radar reflectivity is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot, rc\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature, COLORS\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, to_np, get_cartopy, latlon_coords, vertcross,\n",
    "                 cartopy_xlim, cartopy_ylim, ALL_TIMES, extract_vars,\n",
    "                 omp_set_num_threads, omp_get_num_procs)\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "print(\"Calculating dbz...\")\n",
    "\n",
    "# Get DBZ for all times\n",
    "cache = extract_vars(wrf_file, ALL_TIMES, (\"T\", \"P\", \"PB\", \"QVAPOR\", \n",
    "                                           \"QRAIN\", \"QSNOW\", \"QGRAUP\"))\n",
    "\n",
    "omp_set_num_threads(omp_get_num_procs())\n",
    "\n",
    "dbz_all = getvar(wrf_file, \"mdbz\", timeidx=ALL_TIMES, cache=cache)\n",
    "\n",
    "# Get the cartopy projection object\n",
    "cart_proj = get_cartopy(dbz_all)\n",
    "\n",
    "fig = pyplot.figure(figsize=(8,10))\n",
    "ax = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and create the states and land\n",
    "states = NaturalEarthFeature(category='cultural', scale='50m', facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "land = NaturalEarthFeature(category='physical', name='land', scale='50m',\n",
    "                           facecolor=COLORS['land'])\n",
    "\n",
    "dbz_levels = np.arange(5, 80, 5)\n",
    "num_frames = dbz_all.shape[0]\n",
    "\n",
    "# This is the NWS radar color table\n",
    "dbz_rgb = np.array([[4,233,231],\n",
    "                    [1,159,244], [3, 0, 244],\n",
    "                    [2,253,2], [1,197,1],\n",
    "                    [0,142,0], [253,248,2],\n",
    "                    [229,188,0], [253,149,0],\n",
    "                    [253,0,0], [212,0,0],\n",
    "                    [188,0,0],[248,0,253],\n",
    "                    [152,84,198],[253,253,253]], np.float32) / 255.0\n",
    "    \n",
    "dbz_map, dbz_norm = from_levels_and_colors(dbz_levels, dbz_rgb, extend=\"max\")\n",
    "\n",
    "\n",
    "# This init function is used to set up the colorbar, otherwise it gets \n",
    "# repeatedly drawn.\n",
    "def init():\n",
    "    \n",
    "    dbz = dbz_all[0,:]\n",
    "    \n",
    "    lats, lons = latlon_coords(dbz)\n",
    "    \n",
    "    dbz_contours = ax.contourf(to_np(lons), \n",
    "                               to_np(lats), \n",
    "                               to_np(dbz), \n",
    "                               levels=dbz_levels,\n",
    "                               cmap=dbz_map, \n",
    "                               norm=dbz_norm, \n",
    "                               extend=\"max\",\n",
    "                               zorder=3,\n",
    "                               transform=crs.PlateCarree())\n",
    "    \n",
    "    cb = fig.colorbar(dbz_contours, ax=ax, shrink=.9)\n",
    "    \n",
    "    # Set the map bounds\n",
    "    ax.set_xlim(cartopy_xlim(dbz))\n",
    "    ax.set_ylim(cartopy_ylim(dbz))\n",
    "    \n",
    "    return ax.clear()\n",
    "    \n",
    "\n",
    "print (\"Creating animation. This may take a few minutes...\")\n",
    "\n",
    "# This function is called for each frame of the animation, where\n",
    "# i is the frame index. Here is where the animation frames need \n",
    "# to be created.\n",
    "def animate(i):\n",
    "    if (i%9 == 0 and i > 0):\n",
    "        print(\"Completed frame {}...\".format((10*i)//9))\n",
    "        \n",
    "    ax.clear()\n",
    "    \n",
    "    dbz = dbz_all[i,:]\n",
    "    \n",
    "    # Get the lat/lon coordinates\n",
    "    lats, lons = latlon_coords(dbz)\n",
    "    \n",
    "    ax.add_feature(land)\n",
    "    ax.add_feature(states, linewidth=2.0, edgecolor=\"black\", zorder=3)\n",
    "    \n",
    "    dbz_contours = ax.contourf(to_np(lons), \n",
    "                               to_np(lats), \n",
    "                               to_np(dbz),\n",
    "                               levels=dbz_levels,\n",
    "                               cmap=dbz_map, \n",
    "                               norm=dbz_norm,\n",
    "                               extend=\"max\",\n",
    "                               zorder=3,\n",
    "                               transform=crs.PlateCarree()) \n",
    "    \n",
    "    # Set the map bounds\n",
    "    ax.set_xlim(cartopy_xlim(dbz))\n",
    "    ax.set_ylim(cartopy_ylim(dbz))\n",
    "     \n",
    "    return ax\n",
    "\n",
    "# Create the animation by supplying a figure, the animation object, \n",
    "# the number of frames, the init functions, and an interval in milliseconds \n",
    "# that is the delay between frames.\n",
    "ani = FuncAnimation(fig, animate, num_frames, init_func=init, interval=500)\n",
    "\n",
    "# To work with jupyter notebook, you need to use the HTML generated\n",
    "# by the HTML function from the IPython.display package.\n",
    "# If you change 'to_jshtml' to be 'to_html5_video', you will get an HTML5 \n",
    "# video instead.\n",
    "\n",
    "#HTML(ani.to_html5_video())\n",
    "HTML(ani.to_jshtml())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 7.6: Reducing WRF File Size\n",
    "\n",
    "In your workbook is an iterable class that can be used to reduce file size. \n",
    "\n",
    "Until xarray/dask is supported for the front end, this is one way that you can create domain subsets. \n",
    "\n",
    "We probably won't have time to cover this, so it's my gift to you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, ll_to_xy, CoordPair, GeoBounds, to_np\n",
    "\n",
    "_VARS_TO_KEEP = (\"Times\", \"XLAT\", \"XLONG\", \"XLAT_U\", \"XLAT_V\", \"XLONG_U\", \n",
    "                \"XLONG_V\", \"U\", \"V\", \"W\", \"PH\", \"PHB\", \"T\", \"P\", \"PB\", \"Q2\", \n",
    "                \"T2\", \"PSFC\", \"U10\", \"V10\", \"XTIME\", \"QVAPOR\", \"QCLOUD\", \n",
    "                \"QGRAUP\", \"QRAIN\", \"QSNOW\", \"QICE\", \"MAPFAC_M\", \"MAPFAC_U\",\n",
    "                \"MAPFAC_V\", \"F\", \"HGT\", \"RAINC\", \"RAINSH\", \"RAINNC\", \"I_RAINC\", \"I_RAINNC\")\n",
    "\n",
    "class FileReduce(object):\n",
    "    def __init__(self, filenames, geobounds, tempdir=None, vars_to_keep=None, \n",
    "                 max_pres=None, compress=False, delete=True, reuse=False):\n",
    "        \"\"\"An iterable object for cutting out geographic domains.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            filenames (sequence): A sequence of file paths to the WRF files\n",
    "            \n",
    "            geobounds (GeoBounds): A GeoBounds object defining the region of interest\n",
    "            \n",
    "            tempdir (str): The location to store the temporary cropped data files. If None, tempfile.mkdtemp is used.\n",
    "            \n",
    "            vars_to_keep (sequence): A sequence of variables names to keep from the original file. None for all vars.\n",
    "            \n",
    "            max_press (float): The maximum pressure height level to keep. None for all levels.\n",
    "            \n",
    "            compress(bool): Set to True to enable zlib compression of variables in the output.\n",
    "            \n",
    "            delete (bool): Set to True to delete the temporary directory when FileReduce is garbage collected.\n",
    "            \n",
    "            reuse (bool): Set to True when you want to resuse the files that were previously converted. *tempdir* \n",
    "                must be set to a specific directory that contains the converted files and *delete* must be False.\n",
    "                \n",
    "        \n",
    "        \"\"\"\n",
    "        self._filenames = filenames\n",
    "        self._i = 0\n",
    "        self._geobounds = geobounds\n",
    "        self._delete = delete\n",
    "        self._vars_to_keep = vars_to_keep\n",
    "        self._max_pres = max_pres\n",
    "        self._compress = compress\n",
    "        self._cache = set()\n",
    "        self._own_data = True\n",
    "        self._reuse = reuse\n",
    "        \n",
    "        if tempdir is not None:\n",
    "            if not os.path.exists(tempdir):\n",
    "                os.makedirs(tempdir)\n",
    "            self._tempdir = tempdir\n",
    "            if self._reuse:\n",
    "                self._cache = set((os.path.join(self._tempdir, name) \n",
    "                                   for name in os.listdir(self._tempdir)))\n",
    "        else:\n",
    "            self._tempdir = tempfile.mkdtemp()\n",
    "\n",
    "        self._prev = None\n",
    "        self._set_extents()\n",
    "    \n",
    "    def _set_extents(self):\n",
    "        fname = list(self._filenames)[0]\n",
    "        with Dataset(fname) as ncfile:\n",
    "            lons = [self._geobounds.bottom_left.lon, self._geobounds.top_right.lon]\n",
    "            lats = [self._geobounds.bottom_left.lat, self._geobounds.top_right.lat]\n",
    "            orig_west_east = len(ncfile.dimensions[\"west_east\"])\n",
    "            orig_south_north = len(ncfile.dimensions[\"south_north\"])\n",
    "            orig_bottom_top = len(ncfile.dimensions[\"bottom_top\"])\n",
    "            \n",
    "            # Note: Not handling the moving nest here\n",
    "            # Extra points included around the boundaries to ensure domain is fully included\n",
    "            x_y = ll_to_xy(ncfile, lats, lons, meta=False)\n",
    "            self._start_x = 0 if x_y[0,0] == 0 else x_y[0,0] - 1\n",
    "            self._end_x = orig_west_east - 1 if x_y[0,1] >= orig_west_east - 1 else x_y[0,1] + 1\n",
    "            self._start_y = 0 if x_y[1,0] == 0 else x_y[1,0] - 1\n",
    "            self._end_y = orig_south_north - 1 if x_y[1,1] >= orig_south_north - 1 else x_y[1,1] + 1\n",
    "            \n",
    "            self._west_east = self._end_x - self._start_x + 1\n",
    "            self._west_east_stag = self._west_east + 1\n",
    "            self._south_north = self._end_y - self._start_y + 1\n",
    "            self._south_north_stag = self._south_north + 1\n",
    "            \n",
    "            # Crop the vertical to the specified pressure\n",
    "            if self._max_pres is not None:\n",
    "                pres = getvar(ncfile, \"pressure\")\n",
    "                # Find the lowest terrain height\n",
    "                ter = to_np(getvar(ncfile, \"ter\"))\n",
    "                min_ter = float(np.amin(ter)) + 1\n",
    "                ter_less = ter <= min_ter\n",
    "                ter_less = np.broadcast_to(ter_less, pres.shape)\n",
    "                # For the lowest terrain height, find the lowest vertical index to meet \n",
    "                # the desired pressure level. The lowest terrain height will result in the \n",
    "                # largest vertical spread to find the pressure level.\n",
    "                x = np.transpose(((pres.values <= self._max_pres) & ter_less).nonzero())\n",
    "                self._end_bot_top = np.amin(x, axis=0)[0] \n",
    "                if (self._end_bot_top >= orig_bottom_top):\n",
    "                    self._end_bot_top = orig_bottom_top - 1\n",
    "            else:\n",
    "                self._end_bot_top = orig_bottom_top - 1\n",
    "                \n",
    "            self._bottom_top = self._end_bot_top + 1\n",
    "            self._bottom_top_stag = self._bottom_top + 1\n",
    "            \n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __copy__(self):\n",
    "        cp = type(self).__new__(self.__class__)\n",
    "        cp.__dict__.update(self.__dict__)\n",
    "        cp._own_data = False\n",
    "        cp._delete = False\n",
    "        \n",
    "        return cp\n",
    "    \n",
    "    def __del__(self):\n",
    "        if self._delete:\n",
    "            shutil.rmtree(self._tempdir)\n",
    "    \n",
    "    def reduce(self, fname):\n",
    "        outfilename = os.path.join(self._tempdir, os.path.basename(fname))\n",
    "        \n",
    "        # WRF-Python can iterate over sequences several times during a 'getvar', so a cache is used to \n",
    "        if outfilename in self._cache:\n",
    "            return Dataset(outfilename)\n",
    "        \n",
    "        # New dimension sizes\n",
    "        dim_d = {\"west_east\" : self._west_east,\n",
    "                 \"west_east_stag\" : self._west_east_stag,\n",
    "                 \"south_north\" : self._south_north,\n",
    "                 \"south_north_stag\" : self._south_north_stag,\n",
    "                 \"bottom_top\" : self._bottom_top,\n",
    "                 \"bottom_top_stag\" : self._bottom_top_stag\n",
    "                }\n",
    "        \n",
    "        # Data slice sizes for the 2D dimensions\n",
    "        slice_d = {\"west_east\" : slice(self._start_x, self._end_x + 1),\n",
    "                   \"west_east_stag\" : slice(self._start_x, self._end_x + 2),\n",
    "                   \"south_north\" : slice(self._start_y, self._end_y + 1),\n",
    "                   \"south_north_stag\" : slice(self._start_y, self._end_y + 2),\n",
    "                   \"bottom_top\" : slice(None, self._end_bot_top + 1),\n",
    "                   \"bottom_top_stag\" : slice(None, self._end_bot_top + 2)\n",
    "                  }\n",
    "        \n",
    "        with Dataset(fname) as infile, Dataset(outfilename, mode=\"w\") as outfile:\n",
    "            \n",
    "            # Copy the global attributes\n",
    "            outfile.setncatts(infile.__dict__)\n",
    "\n",
    "            # Copy Dimensions, limiting south_north and west_east to desired domain\n",
    "            for name, dimension in infile.dimensions.items():\n",
    "                dimsize = dim_d.get(name, len(dimension))\n",
    "                outfile.createDimension(name, dimsize)\n",
    "\n",
    "            # Copy Variables  \n",
    "            for name, variable in infile.variables.iteritems():\n",
    "                if self._vars_to_keep is not None:\n",
    "                    if name not in self._vars_to_keep:\n",
    "                        continue\n",
    "                \n",
    "                print (name)\n",
    "                new_slices = tuple((slice_d.get(dimname, slice(None)) for dimname in variable.dimensions))\n",
    "\n",
    "                outvar = outfile.createVariable(name, variable.datatype, variable.dimensions, zlib=self._compress)\n",
    "\n",
    "                outvar[:] = variable[new_slices]\n",
    "\n",
    "                outvar.setncatts(variable.__dict__)\n",
    "                \n",
    "        \n",
    "        result = Dataset(outfilename)\n",
    "            \n",
    "        self._cache.add(outfilename)\n",
    "            \n",
    "        return result\n",
    "            \n",
    "    \n",
    "    def next(self):\n",
    "        if self._i >= len(self._filenames):\n",
    "            if self._prev is not None:\n",
    "                self._prev.close()\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            fname = self._filenames[self._i]\n",
    "            reduced_file = self.reduce(fname)\n",
    "            if self._prev is not None:\n",
    "                self._prev.close()\n",
    "            self._prev = reduced_file\n",
    "            \n",
    "            self._i += 1\n",
    "            \n",
    "            return reduced_file\n",
    "    \n",
    "    # Python 3\n",
    "    def __next__(self):\n",
    "        return self.next()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "transition": "zoom",
   "width": 1152
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
